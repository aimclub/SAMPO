{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "input_parameters = 14\n",
    "layer_size = 5\n",
    "layer_count = 3\n",
    "classification_size = 3\n",
    "learning_rate = 0.001"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T12:00:44.782274200Z",
     "start_time": "2023-08-28T12:00:44.769432500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "[Parameter containing:\n tensor([[-0.0691,  0.1352,  0.1247, -0.2537, -0.2413, -0.1033, -0.1518,  0.0556,\n          -0.0243, -0.1494,  0.2609, -0.0676, -0.2644,  0.2316],\n         [ 0.0029, -0.0088, -0.1652, -0.2400, -0.2575,  0.0456, -0.1002, -0.1984,\n           0.0763, -0.1753,  0.2422,  0.0075,  0.1864,  0.1682],\n         [-0.1226, -0.2286, -0.1690,  0.0404,  0.2097,  0.1984, -0.2378,  0.2433,\n           0.2395,  0.0801, -0.2059,  0.0902,  0.2476,  0.0284],\n         [ 0.1624,  0.0960, -0.0101,  0.1003,  0.0822, -0.0283,  0.0570,  0.0274,\n           0.1683,  0.2641, -0.0823, -0.2245, -0.1771, -0.1483],\n         [-0.0061, -0.1509,  0.0289, -0.1174,  0.1921, -0.2529, -0.2300, -0.0194,\n           0.0622,  0.1215, -0.2128,  0.1796,  0.1978, -0.1991]],\n        requires_grad=True),\n Parameter containing:\n tensor([-0.2307,  0.2033,  0.1375, -0.1043, -0.2156], requires_grad=True)]"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sampo.scheduler.selection.neural_net import NeuralNet, load_dataset\n",
    "\n",
    "model = NeuralNet(input_parameters, layer_size, layer_count, classification_size)\n",
    "list(model.parameters())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T09:55:59.785439600Z",
     "start_time": "2023-08-28T09:55:57.520980300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Step [100/112], Loss: 1.1774\n",
      "Epoch [2/100], Step [100/112], Loss: 1.1774\n",
      "Epoch [3/100], Step [100/112], Loss: 1.1774\n",
      "Epoch [4/100], Step [100/112], Loss: 1.1774\n",
      "Epoch [5/100], Step [100/112], Loss: 1.1774\n",
      "Epoch [6/100], Step [100/112], Loss: 1.1774\n",
      "Epoch [7/100], Step [100/112], Loss: 1.1774\n",
      "Epoch [8/100], Step [100/112], Loss: 1.1774\n",
      "Epoch [9/100], Step [100/112], Loss: 1.1774\n",
      "Epoch [10/100], Step [100/112], Loss: 1.1774\n",
      "Epoch [11/100], Step [100/112], Loss: 1.1774\n",
      "Epoch [12/100], Step [100/112], Loss: 1.1774\n",
      "Epoch [13/100], Step [100/112], Loss: 1.1774\n",
      "Epoch [14/100], Step [100/112], Loss: 1.1774\n",
      "Epoch [15/100], Step [100/112], Loss: 1.1774\n",
      "Epoch [16/100], Step [100/112], Loss: 1.1774\n",
      "Epoch [17/100], Step [100/112], Loss: 1.1774\n",
      "Epoch [18/100], Step [100/112], Loss: 1.1774\n",
      "Epoch [19/100], Step [100/112], Loss: 1.1774\n",
      "Epoch [20/100], Step [100/112], Loss: 1.1774\n",
      "Epoch [21/100], Step [100/112], Loss: 1.1774\n",
      "Epoch [22/100], Step [100/112], Loss: 1.1774\n",
      "Epoch [23/100], Step [100/112], Loss: 1.1774\n",
      "Epoch [24/100], Step [100/112], Loss: 1.1774\n",
      "Epoch [25/100], Step [100/112], Loss: 1.1774\n",
      "Epoch [26/100], Step [100/112], Loss: 1.1774\n",
      "Epoch [27/100], Step [100/112], Loss: 1.1774\n",
      "Epoch [28/100], Step [100/112], Loss: 1.1774\n",
      "Epoch [29/100], Step [100/112], Loss: 1.1774\n",
      "Epoch [30/100], Step [100/112], Loss: 1.1774\n",
      "Epoch [31/100], Step [100/112], Loss: 1.1774\n",
      "Epoch [32/100], Step [100/112], Loss: 1.1774\n",
      "Epoch [33/100], Step [100/112], Loss: 1.1774\n",
      "Epoch [34/100], Step [100/112], Loss: 1.1774\n",
      "Epoch [35/100], Step [100/112], Loss: 1.1774\n",
      "Epoch [36/100], Step [100/112], Loss: 1.1774\n",
      "Epoch [37/100], Step [100/112], Loss: 1.1774\n",
      "Epoch [38/100], Step [100/112], Loss: 1.1774\n",
      "Epoch [39/100], Step [100/112], Loss: 1.1774\n",
      "Epoch [40/100], Step [100/112], Loss: 1.1774\n",
      "Epoch [41/100], Step [100/112], Loss: 1.1774\n",
      "Epoch [42/100], Step [100/112], Loss: 1.1774\n",
      "Epoch [43/100], Step [100/112], Loss: 1.1774\n",
      "Epoch [44/100], Step [100/112], Loss: 1.1774\n",
      "Epoch [45/100], Step [100/112], Loss: 1.1774\n",
      "Epoch [46/100], Step [100/112], Loss: 1.1774\n",
      "Epoch [47/100], Step [100/112], Loss: 1.1774\n",
      "Epoch [48/100], Step [100/112], Loss: 1.1774\n",
      "Epoch [49/100], Step [100/112], Loss: 1.1774\n",
      "Epoch [50/100], Step [100/112], Loss: 1.1774\n",
      "Epoch [51/100], Step [100/112], Loss: 1.1774\n",
      "Epoch [52/100], Step [100/112], Loss: 1.1774\n",
      "Epoch [53/100], Step [100/112], Loss: 1.1774\n",
      "Epoch [54/100], Step [100/112], Loss: 1.1774\n",
      "Epoch [55/100], Step [100/112], Loss: 1.1774\n",
      "Epoch [56/100], Step [100/112], Loss: 1.1774\n",
      "Epoch [57/100], Step [100/112], Loss: 1.1774\n",
      "Epoch [58/100], Step [100/112], Loss: 1.1774\n",
      "Epoch [59/100], Step [100/112], Loss: 1.1774\n",
      "Epoch [60/100], Step [100/112], Loss: 1.1774\n",
      "Epoch [61/100], Step [100/112], Loss: 1.1774\n",
      "Epoch [62/100], Step [100/112], Loss: 1.1774\n",
      "Epoch [63/100], Step [100/112], Loss: 1.1774\n",
      "Epoch [64/100], Step [100/112], Loss: 1.1774\n",
      "Epoch [65/100], Step [100/112], Loss: 1.1774\n",
      "Epoch [66/100], Step [100/112], Loss: 1.1774\n",
      "Epoch [67/100], Step [100/112], Loss: 1.5514\n",
      "Epoch [68/100], Step [100/112], Loss: 1.5514\n",
      "Epoch [69/100], Step [100/112], Loss: 1.5514\n",
      "Epoch [70/100], Step [100/112], Loss: 1.5514\n",
      "Epoch [71/100], Step [100/112], Loss: 1.5514\n",
      "Epoch [72/100], Step [100/112], Loss: 1.5514\n",
      "Epoch [73/100], Step [100/112], Loss: 1.5514\n",
      "Epoch [74/100], Step [100/112], Loss: 1.5514\n",
      "Epoch [75/100], Step [100/112], Loss: 1.5514\n",
      "Epoch [76/100], Step [100/112], Loss: 1.5514\n",
      "Epoch [77/100], Step [100/112], Loss: 1.5514\n",
      "Epoch [78/100], Step [100/112], Loss: 1.5514\n",
      "Epoch [79/100], Step [100/112], Loss: 1.5514\n",
      "Epoch [80/100], Step [100/112], Loss: 1.5514\n",
      "Epoch [81/100], Step [100/112], Loss: 1.5514\n",
      "Epoch [82/100], Step [100/112], Loss: 1.5514\n",
      "Epoch [83/100], Step [100/112], Loss: 1.5514\n",
      "Epoch [84/100], Step [100/112], Loss: 1.5514\n",
      "Epoch [85/100], Step [100/112], Loss: 1.5514\n",
      "Epoch [86/100], Step [100/112], Loss: 1.5514\n",
      "Epoch [87/100], Step [100/112], Loss: 1.5514\n",
      "Epoch [88/100], Step [100/112], Loss: 1.5514\n",
      "Epoch [89/100], Step [100/112], Loss: 1.5514\n",
      "Epoch [90/100], Step [100/112], Loss: 1.5514\n",
      "Epoch [91/100], Step [100/112], Loss: 1.5514\n",
      "Epoch [92/100], Step [100/112], Loss: 1.5514\n",
      "Epoch [93/100], Step [100/112], Loss: 1.5514\n",
      "Epoch [94/100], Step [100/112], Loss: 1.5514\n",
      "Epoch [95/100], Step [100/112], Loss: 1.5514\n",
      "Epoch [96/100], Step [100/112], Loss: 1.5514\n",
      "Epoch [97/100], Step [100/112], Loss: 1.5514\n",
      "Epoch [98/100], Step [100/112], Loss: 1.5514\n",
      "Epoch [99/100], Step [100/112], Loss: 1.5514\n",
      "Epoch [100/100], Step [100/112], Loss: 1.5514\n"
     ]
    },
    {
     "data": {
      "text/plain": "[Parameter containing:\n tensor([[-0.0691,  0.1352,  0.1247, -0.2537, -0.2413, -0.1033, -0.1518,  0.0556,\n          -0.0243, -0.1494,  0.2609, -0.0676, -0.2644,  0.2316],\n         [-0.0212, -0.0982, -0.1943, -0.3198, -0.2866, -0.0223, -0.1681, -0.2480,\n           0.0589, -0.1874,  0.2130, -0.0134,  0.1277,  0.1683],\n         [-0.0054, -0.1252, -0.0687,  0.1499,  0.3100,  0.3078, -0.1284,  0.3588,\n           0.3308,  0.1882, -0.0790,  0.2190,  0.3863,  0.0284],\n         [ 0.1481,  0.0452, -0.0480,  0.0666,  0.0444, -0.0436,  0.0416,  0.0121,\n           0.1300,  0.2913, -0.0551, -0.1825, -0.1771, -0.1483],\n         [ 0.0759,  0.0777,  0.1365,  0.0896,  0.2997, -0.0695, -0.0466,  0.1189,\n           0.1699,  0.1900, -0.1352,  0.2407,  0.2841, -0.1992]],\n        requires_grad=True),\n Parameter containing:\n tensor([-0.2307,  0.1354,  0.2469, -0.1197, -0.0323], requires_grad=True)]"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for i in range(10):\n",
    "#     print(f'Loop {i}/10')\n",
    "x_train, x_test, y_train, y_test = load_dataset('dataset.csv')\n",
    "model.fit(x_train, y_train, 100)\n",
    "list(model.parameters())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T09:56:05.951294200Z",
     "start_time": "2023-08-28T09:55:59.790510200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "[tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.])]"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T09:50:30.066493400Z",
     "start_time": "2023-08-28T09:50:30.023432100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 38 test images: 34.21052631578947 %\n"
     ]
    }
   ],
   "source": [
    "model.score(x_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T09:56:10.170862200Z",
     "start_time": "2023-08-28T09:56:10.150699800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sampo.scheduler.selection.neural_net import NeuralNet\n",
    "\n",
    "train_dataset = pd.read_csv('dataset.csv', index_col='index')\n",
    "for col in train_dataset.columns[:-1]:\n",
    "    train_dataset[col] = train_dataset[col].apply(lambda x: float(x))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T16:32:34.806195Z",
     "start_time": "2023-08-28T16:32:32.435450900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "input_parameters = 14\n",
    "layer_size = 5\n",
    "layer_count = 3\n",
    "classification_size = 3\n",
    "learning_rate = 0.0001\n",
    "\n",
    "model = NeuralNet(input_parameters, layer_size, layer_count, classification_size, learning_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T16:32:34.831185300Z",
     "start_time": "2023-08-28T16:32:34.807191800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "           0         1     2          3     4    5    6    7      8      9  \\\nindex                                                                        \n23     144.0  0.836006  47.0  30.027778  47.0  1.0  1.0  3.0   95.0  546.0   \n20      43.0  1.155889  27.0  34.569767  27.0  1.0  1.0  2.0   53.0  183.0   \n38     134.0  0.905647  45.0  31.690299  45.0  1.0  1.0  3.0   91.0  502.0   \n24     141.0  0.895396  46.0  30.223404  46.0  1.0  1.0  3.0   93.0  560.0   \n9       42.0  1.630476  27.0  41.690476  27.0  1.0  1.0  2.0   53.0  167.0   \n...      ...       ...   ...        ...   ...  ...  ...  ...    ...    ...   \n114    164.0  0.862117  62.0  30.298780  62.0  1.0  1.0  3.0   78.0  328.0   \n123    170.0  0.757520  64.0  29.217647  64.0  1.0  1.0  4.0  129.0  565.0   \n113    211.0  0.690505  88.0  27.419431  88.0  1.0  1.0  3.0   74.0  578.0   \n144    193.0  0.736276  76.0  28.813472  76.0  1.0  1.0  3.0   58.0  570.0   \n140    166.0  0.682447  80.0  26.451807  80.0  1.0  1.0  3.0   72.0  342.0   \n\n           10      11     12   13  label  \nindex                                     \n23      933.0  1193.0  338.0  0.0      0  \n20      183.0   146.0    0.0  0.0      0  \n38      853.0  1089.0  306.0  0.0      0  \n24      791.0  1055.0  178.0  0.0      0  \n9       167.0   130.0    0.0  0.0      0  \n...       ...     ...    ...  ...    ...  \n114     956.0   984.0  612.0  0.0      2  \n123    1025.0  1221.0  386.0  0.0      2  \n113    1356.0  1612.0  772.0  0.0      2  \n144    1332.0  1652.0  772.0  0.0      2  \n140     784.0   808.0  420.0  0.0      2  \n\n[150 rows x 15 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n      <th>label</th>\n    </tr>\n    <tr>\n      <th>index</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>23</th>\n      <td>144.0</td>\n      <td>0.836006</td>\n      <td>47.0</td>\n      <td>30.027778</td>\n      <td>47.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>95.0</td>\n      <td>546.0</td>\n      <td>933.0</td>\n      <td>1193.0</td>\n      <td>338.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>43.0</td>\n      <td>1.155889</td>\n      <td>27.0</td>\n      <td>34.569767</td>\n      <td>27.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>53.0</td>\n      <td>183.0</td>\n      <td>183.0</td>\n      <td>146.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>134.0</td>\n      <td>0.905647</td>\n      <td>45.0</td>\n      <td>31.690299</td>\n      <td>45.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>91.0</td>\n      <td>502.0</td>\n      <td>853.0</td>\n      <td>1089.0</td>\n      <td>306.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>141.0</td>\n      <td>0.895396</td>\n      <td>46.0</td>\n      <td>30.223404</td>\n      <td>46.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>93.0</td>\n      <td>560.0</td>\n      <td>791.0</td>\n      <td>1055.0</td>\n      <td>178.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>42.0</td>\n      <td>1.630476</td>\n      <td>27.0</td>\n      <td>41.690476</td>\n      <td>27.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>53.0</td>\n      <td>167.0</td>\n      <td>167.0</td>\n      <td>130.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>114</th>\n      <td>164.0</td>\n      <td>0.862117</td>\n      <td>62.0</td>\n      <td>30.298780</td>\n      <td>62.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>78.0</td>\n      <td>328.0</td>\n      <td>956.0</td>\n      <td>984.0</td>\n      <td>612.0</td>\n      <td>0.0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>123</th>\n      <td>170.0</td>\n      <td>0.757520</td>\n      <td>64.0</td>\n      <td>29.217647</td>\n      <td>64.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>129.0</td>\n      <td>565.0</td>\n      <td>1025.0</td>\n      <td>1221.0</td>\n      <td>386.0</td>\n      <td>0.0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>113</th>\n      <td>211.0</td>\n      <td>0.690505</td>\n      <td>88.0</td>\n      <td>27.419431</td>\n      <td>88.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>74.0</td>\n      <td>578.0</td>\n      <td>1356.0</td>\n      <td>1612.0</td>\n      <td>772.0</td>\n      <td>0.0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>144</th>\n      <td>193.0</td>\n      <td>0.736276</td>\n      <td>76.0</td>\n      <td>28.813472</td>\n      <td>76.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>58.0</td>\n      <td>570.0</td>\n      <td>1332.0</td>\n      <td>1652.0</td>\n      <td>772.0</td>\n      <td>0.0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>140</th>\n      <td>166.0</td>\n      <td>0.682447</td>\n      <td>80.0</td>\n      <td>26.451807</td>\n      <td>80.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>72.0</td>\n      <td>342.0</td>\n      <td>784.0</td>\n      <td>808.0</td>\n      <td>420.0</td>\n      <td>0.0</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>150 rows Ã— 15 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T16:32:34.869014200Z",
     "start_time": "2023-08-28T16:32:34.841489400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [2/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [3/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [4/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [5/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [6/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [7/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [8/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [9/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [10/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [11/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [12/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [13/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [14/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [15/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [16/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [17/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [18/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [19/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [20/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [21/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [22/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [23/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [24/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [25/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [26/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [27/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [28/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [29/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [30/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [31/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [32/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [33/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [34/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [35/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [36/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [37/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [38/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [39/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [40/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [41/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [42/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [43/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [44/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [45/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [46/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [47/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [48/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [49/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [50/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [51/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [52/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [53/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [54/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [55/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [56/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [57/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [58/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [59/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [60/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [61/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [62/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [63/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [64/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [65/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [66/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [67/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [68/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [69/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [70/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [71/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [72/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [73/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [74/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [75/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [76/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [77/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [78/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [79/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [80/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [81/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [82/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [83/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [84/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [85/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [86/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [87/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [88/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [89/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [90/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [91/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [92/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [93/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [94/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [95/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [96/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [97/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [98/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [99/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [100/100], Step [100/135], Loss: 0.5514\n",
      "Test set: Average loss: 0.0368, Accuracy: 5/15 (33.33%)\n",
      "\n",
      "Epoch [1/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [2/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [3/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [4/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [5/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [6/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [7/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [8/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [9/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [10/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [11/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [12/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [13/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [14/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [15/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [16/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [17/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [18/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [19/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [20/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [21/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [22/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [23/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [24/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [25/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [26/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [27/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [28/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [29/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [30/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [31/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [32/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [33/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [34/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [35/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [36/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [37/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [38/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [39/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [40/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [41/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [42/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [43/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [44/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [45/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [46/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [47/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [48/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [49/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [50/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [51/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [52/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [53/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [54/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [55/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [56/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [57/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [58/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [59/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [60/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [61/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [62/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [63/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [64/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [65/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [66/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [67/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [68/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [69/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [70/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [71/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [72/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [73/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [74/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [75/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [76/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [77/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [78/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [79/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [80/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [81/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [82/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [83/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [84/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [85/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [86/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [87/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [88/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [89/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [90/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [91/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [92/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [93/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [94/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [95/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [96/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [97/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [98/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [99/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [100/100], Step [100/135], Loss: 1.5514\n",
      "Test set: Average loss: 0.0368, Accuracy: 6/15 (40.00%)\n",
      "\n",
      "Epoch [1/100], Step [100/135], Loss: 0.5520\n",
      "Epoch [2/100], Step [100/135], Loss: 0.5520\n",
      "Epoch [3/100], Step [100/135], Loss: 0.5521\n",
      "Epoch [4/100], Step [100/135], Loss: 0.5521\n",
      "Epoch [5/100], Step [100/135], Loss: 0.5522\n",
      "Epoch [6/100], Step [100/135], Loss: 0.5522\n",
      "Epoch [7/100], Step [100/135], Loss: 0.5523\n",
      "Epoch [8/100], Step [100/135], Loss: 0.5523\n",
      "Epoch [9/100], Step [100/135], Loss: 0.5524\n",
      "Epoch [10/100], Step [100/135], Loss: 0.5524\n",
      "Epoch [11/100], Step [100/135], Loss: 0.5525\n",
      "Epoch [12/100], Step [100/135], Loss: 0.5526\n",
      "Epoch [13/100], Step [100/135], Loss: 0.5527\n",
      "Epoch [14/100], Step [100/135], Loss: 0.5527\n",
      "Epoch [15/100], Step [100/135], Loss: 0.5528\n",
      "Epoch [16/100], Step [100/135], Loss: 0.5529\n",
      "Epoch [17/100], Step [100/135], Loss: 0.5530\n",
      "Epoch [18/100], Step [100/135], Loss: 0.5531\n",
      "Epoch [19/100], Step [100/135], Loss: 0.5533\n",
      "Epoch [20/100], Step [100/135], Loss: 0.5534\n",
      "Epoch [21/100], Step [100/135], Loss: 0.5536\n",
      "Epoch [22/100], Step [100/135], Loss: 0.5537\n",
      "Epoch [23/100], Step [100/135], Loss: 0.5539\n",
      "Epoch [24/100], Step [100/135], Loss: 0.5541\n",
      "Epoch [25/100], Step [100/135], Loss: 0.5544\n",
      "Epoch [26/100], Step [100/135], Loss: 0.5546\n",
      "Epoch [27/100], Step [100/135], Loss: 0.5549\n",
      "Epoch [28/100], Step [100/135], Loss: 0.5553\n",
      "Epoch [29/100], Step [100/135], Loss: 0.5558\n",
      "Epoch [30/100], Step [100/135], Loss: 0.5563\n",
      "Epoch [31/100], Step [100/135], Loss: 0.5548\n",
      "Epoch [32/100], Step [100/135], Loss: 0.5553\n",
      "Epoch [33/100], Step [100/135], Loss: 0.5559\n",
      "Epoch [34/100], Step [100/135], Loss: 0.5567\n",
      "Epoch [35/100], Step [100/135], Loss: 0.5552\n",
      "Epoch [36/100], Step [100/135], Loss: 0.5559\n",
      "Epoch [37/100], Step [100/135], Loss: 0.5568\n",
      "Epoch [38/100], Step [100/135], Loss: 0.5553\n",
      "Epoch [39/100], Step [100/135], Loss: 0.5562\n",
      "Epoch [40/100], Step [100/135], Loss: 0.5550\n",
      "Epoch [41/100], Step [100/135], Loss: 0.5558\n",
      "Epoch [42/100], Step [100/135], Loss: 0.5568\n",
      "Epoch [43/100], Step [100/135], Loss: 0.5555\n",
      "Epoch [44/100], Step [100/135], Loss: 0.5564\n",
      "Epoch [45/100], Step [100/135], Loss: 0.5553\n",
      "Epoch [46/100], Step [100/135], Loss: 0.5562\n",
      "Epoch [47/100], Step [100/135], Loss: 0.5574\n",
      "Epoch [48/100], Step [100/135], Loss: 0.5560\n",
      "Epoch [49/100], Step [100/135], Loss: 0.5573\n",
      "Epoch [50/100], Step [100/135], Loss: 0.5560\n",
      "Epoch [51/100], Step [100/135], Loss: 0.5572\n",
      "Epoch [52/100], Step [100/135], Loss: 0.5560\n",
      "Epoch [53/100], Step [100/135], Loss: 0.5573\n",
      "Epoch [54/100], Step [100/135], Loss: 0.5561\n",
      "Epoch [55/100], Step [100/135], Loss: 0.5575\n",
      "Epoch [56/100], Step [100/135], Loss: 0.5563\n",
      "Epoch [57/100], Step [100/135], Loss: 0.5578\n",
      "Epoch [58/100], Step [100/135], Loss: 0.5565\n",
      "Epoch [59/100], Step [100/135], Loss: 0.5582\n",
      "Epoch [60/100], Step [100/135], Loss: 0.5569\n",
      "Epoch [61/100], Step [100/135], Loss: 0.5588\n",
      "Epoch [62/100], Step [100/135], Loss: 0.5568\n",
      "Epoch [63/100], Step [100/135], Loss: 0.5588\n",
      "Epoch [64/100], Step [100/135], Loss: 0.5575\n",
      "Epoch [65/100], Step [100/135], Loss: 0.5598\n",
      "Epoch [66/100], Step [100/135], Loss: 0.5579\n",
      "Epoch [67/100], Step [100/135], Loss: 0.5570\n",
      "Epoch [68/100], Step [100/135], Loss: 0.5592\n",
      "Epoch [69/100], Step [100/135], Loss: 0.5580\n",
      "Epoch [70/100], Step [100/135], Loss: 0.5607\n",
      "Epoch [71/100], Step [100/135], Loss: 0.5589\n",
      "Epoch [72/100], Step [100/135], Loss: 0.5579\n",
      "Epoch [73/100], Step [100/135], Loss: 0.5608\n",
      "Epoch [74/100], Step [100/135], Loss: 0.5591\n",
      "Epoch [75/100], Step [100/135], Loss: 0.5582\n",
      "Epoch [76/100], Step [100/135], Loss: 0.5613\n",
      "Epoch [77/100], Step [100/135], Loss: 0.5596\n",
      "Epoch [78/100], Step [100/135], Loss: 0.5588\n",
      "Epoch [79/100], Step [100/135], Loss: 0.5625\n",
      "Epoch [80/100], Step [100/135], Loss: 0.5608\n",
      "Epoch [81/100], Step [100/135], Loss: 0.5591\n",
      "Epoch [82/100], Step [100/135], Loss: 0.5632\n",
      "Epoch [83/100], Step [100/135], Loss: 0.5617\n",
      "Epoch [84/100], Step [100/135], Loss: 0.5604\n",
      "Epoch [85/100], Step [100/135], Loss: 0.5598\n",
      "Epoch [86/100], Step [100/135], Loss: 0.5594\n",
      "Epoch [87/100], Step [100/135], Loss: 0.5641\n",
      "Epoch [88/100], Step [100/135], Loss: 0.5627\n",
      "Epoch [89/100], Step [100/135], Loss: 0.5615\n",
      "Epoch [90/100], Step [100/135], Loss: 0.5612\n",
      "Epoch [91/100], Step [100/135], Loss: 0.5609\n",
      "Epoch [92/100], Step [100/135], Loss: 0.5606\n",
      "Epoch [93/100], Step [100/135], Loss: 0.5669\n",
      "Epoch [94/100], Step [100/135], Loss: 0.5614\n",
      "Epoch [95/100], Step [100/135], Loss: 0.5614\n",
      "Epoch [96/100], Step [100/135], Loss: 0.5687\n",
      "Epoch [97/100], Step [100/135], Loss: 0.5629\n",
      "Epoch [98/100], Step [100/135], Loss: 0.5632\n",
      "Epoch [99/100], Step [100/135], Loss: 0.5635\n",
      "Epoch [100/100], Step [100/135], Loss: 0.5640\n",
      "Test set: Average loss: 0.0368, Accuracy: 5/15 (33.33%)\n",
      "\n",
      "Epoch [1/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [2/100], Step [100/135], Loss: 0.5514\n",
      "Epoch [3/100], Step [100/135], Loss: 0.5515\n",
      "Epoch [4/100], Step [100/135], Loss: 0.5515\n",
      "Epoch [5/100], Step [100/135], Loss: 0.5557\n",
      "Epoch [6/100], Step [100/135], Loss: 0.5631\n",
      "Epoch [7/100], Step [100/135], Loss: 0.6210\n",
      "Epoch [8/100], Step [100/135], Loss: 0.7576\n",
      "Epoch [9/100], Step [100/135], Loss: 0.7836\n",
      "Epoch [10/100], Step [100/135], Loss: 0.7841\n",
      "Epoch [11/100], Step [100/135], Loss: 0.7844\n",
      "Epoch [12/100], Step [100/135], Loss: 0.7848\n",
      "Epoch [13/100], Step [100/135], Loss: 0.7851\n",
      "Epoch [14/100], Step [100/135], Loss: 0.7853\n",
      "Epoch [15/100], Step [100/135], Loss: 0.7856\n",
      "Epoch [16/100], Step [100/135], Loss: 0.7713\n",
      "Epoch [17/100], Step [100/135], Loss: 0.7715\n",
      "Epoch [18/100], Step [100/135], Loss: 0.7609\n",
      "Epoch [19/100], Step [100/135], Loss: 0.7611\n",
      "Epoch [20/100], Step [100/135], Loss: 0.7614\n",
      "Epoch [21/100], Step [100/135], Loss: 0.7617\n",
      "Epoch [22/100], Step [100/135], Loss: 0.7620\n",
      "Epoch [23/100], Step [100/135], Loss: 0.7622\n",
      "Epoch [24/100], Step [100/135], Loss: 0.7624\n",
      "Epoch [25/100], Step [100/135], Loss: 0.7626\n",
      "Epoch [26/100], Step [100/135], Loss: 0.7628\n",
      "Epoch [27/100], Step [100/135], Loss: 0.7630\n",
      "Epoch [28/100], Step [100/135], Loss: 0.7631\n",
      "Epoch [29/100], Step [100/135], Loss: 0.7632\n",
      "Epoch [30/100], Step [100/135], Loss: 0.7634\n",
      "Epoch [31/100], Step [100/135], Loss: 0.7985\n",
      "Epoch [32/100], Step [100/135], Loss: 0.7972\n",
      "Epoch [33/100], Step [100/135], Loss: 0.7970\n",
      "Epoch [34/100], Step [100/135], Loss: 0.8052\n",
      "Epoch [35/100], Step [100/135], Loss: 0.8056\n",
      "Epoch [36/100], Step [100/135], Loss: 0.8061\n",
      "Epoch [37/100], Step [100/135], Loss: 0.8066\n",
      "Epoch [38/100], Step [100/135], Loss: 0.8071\n",
      "Epoch [39/100], Step [100/135], Loss: 0.8076\n",
      "Epoch [40/100], Step [100/135], Loss: 0.8081\n",
      "Epoch [41/100], Step [100/135], Loss: 0.8086\n",
      "Epoch [42/100], Step [100/135], Loss: 0.8091\n",
      "Epoch [43/100], Step [100/135], Loss: 0.8095\n",
      "Epoch [44/100], Step [100/135], Loss: 0.7768\n",
      "Epoch [45/100], Step [100/135], Loss: 0.7771\n",
      "Epoch [46/100], Step [100/135], Loss: 0.7776\n",
      "Epoch [47/100], Step [100/135], Loss: 0.7780\n",
      "Epoch [48/100], Step [100/135], Loss: 0.7784\n",
      "Epoch [49/100], Step [100/135], Loss: 0.7787\n",
      "Epoch [50/100], Step [100/135], Loss: 0.7789\n",
      "Epoch [51/100], Step [100/135], Loss: 0.7790\n",
      "Epoch [52/100], Step [100/135], Loss: 0.7791\n",
      "Epoch [53/100], Step [100/135], Loss: 0.7792\n",
      "Epoch [54/100], Step [100/135], Loss: 0.7792\n",
      "Epoch [55/100], Step [100/135], Loss: 0.7792\n",
      "Epoch [56/100], Step [100/135], Loss: 0.7791\n",
      "Epoch [57/100], Step [100/135], Loss: 0.7790\n",
      "Epoch [58/100], Step [100/135], Loss: 0.7789\n",
      "Epoch [59/100], Step [100/135], Loss: 0.7788\n",
      "Epoch [60/100], Step [100/135], Loss: 0.7787\n",
      "Epoch [61/100], Step [100/135], Loss: 0.7785\n",
      "Epoch [62/100], Step [100/135], Loss: 0.7743\n",
      "Epoch [63/100], Step [100/135], Loss: 0.7741\n",
      "Epoch [64/100], Step [100/135], Loss: 0.7739\n",
      "Epoch [65/100], Step [100/135], Loss: 0.7755\n",
      "Epoch [66/100], Step [100/135], Loss: 0.7753\n",
      "Epoch [67/100], Step [100/135], Loss: 0.7750\n",
      "Epoch [68/100], Step [100/135], Loss: 0.7748\n",
      "Epoch [69/100], Step [100/135], Loss: 0.7838\n",
      "Epoch [70/100], Step [100/135], Loss: 0.7819\n",
      "Epoch [71/100], Step [100/135], Loss: 0.7819\n",
      "Epoch [72/100], Step [100/135], Loss: 0.7820\n",
      "Epoch [73/100], Step [100/135], Loss: 0.7821\n",
      "Epoch [74/100], Step [100/135], Loss: 0.7821\n",
      "Epoch [75/100], Step [100/135], Loss: 0.7822\n",
      "Epoch [76/100], Step [100/135], Loss: 0.7823\n",
      "Epoch [77/100], Step [100/135], Loss: 0.7582\n",
      "Epoch [78/100], Step [100/135], Loss: 0.7813\n",
      "Epoch [79/100], Step [100/135], Loss: 0.7577\n",
      "Epoch [80/100], Step [100/135], Loss: 0.7569\n",
      "Epoch [81/100], Step [100/135], Loss: 0.7567\n",
      "Epoch [82/100], Step [100/135], Loss: 0.7564\n",
      "Epoch [83/100], Step [100/135], Loss: 0.7561\n",
      "Epoch [84/100], Step [100/135], Loss: 0.7558\n",
      "Epoch [85/100], Step [100/135], Loss: 0.7555\n",
      "Epoch [86/100], Step [100/135], Loss: 0.7552\n",
      "Epoch [87/100], Step [100/135], Loss: 0.7697\n",
      "Epoch [88/100], Step [100/135], Loss: 0.7549\n",
      "Epoch [89/100], Step [100/135], Loss: 0.7540\n",
      "Epoch [90/100], Step [100/135], Loss: 0.7536\n",
      "Epoch [91/100], Step [100/135], Loss: 0.7533\n",
      "Epoch [92/100], Step [100/135], Loss: 0.7528\n",
      "Epoch [93/100], Step [100/135], Loss: 0.7524\n",
      "Epoch [94/100], Step [100/135], Loss: 0.7520\n",
      "Epoch [95/100], Step [100/135], Loss: 0.7582\n",
      "Epoch [96/100], Step [100/135], Loss: 0.7586\n",
      "Epoch [97/100], Step [100/135], Loss: 0.7588\n",
      "Epoch [98/100], Step [100/135], Loss: 0.7584\n",
      "Epoch [99/100], Step [100/135], Loss: 0.7583\n",
      "Epoch [100/100], Step [100/135], Loss: 0.7582\n",
      "Test set: Average loss: 0.1034, Accuracy: 6/15 (40.00%)\n",
      "\n",
      "Epoch [1/100], Step [100/135], Loss: 1.0468\n",
      "Epoch [2/100], Step [100/135], Loss: 1.3434\n",
      "Epoch [3/100], Step [100/135], Loss: 1.4149\n",
      "Epoch [4/100], Step [100/135], Loss: 1.4045\n",
      "Epoch [5/100], Step [100/135], Loss: 1.4035\n",
      "Epoch [6/100], Step [100/135], Loss: 1.4037\n",
      "Epoch [7/100], Step [100/135], Loss: 1.4040\n",
      "Epoch [8/100], Step [100/135], Loss: 1.4042\n",
      "Epoch [9/100], Step [100/135], Loss: 1.4044\n",
      "Epoch [10/100], Step [100/135], Loss: 1.4045\n",
      "Epoch [11/100], Step [100/135], Loss: 1.4046\n",
      "Epoch [12/100], Step [100/135], Loss: 1.4047\n",
      "Epoch [13/100], Step [100/135], Loss: 1.4048\n",
      "Epoch [14/100], Step [100/135], Loss: 1.4049\n",
      "Epoch [15/100], Step [100/135], Loss: 1.4050\n",
      "Epoch [16/100], Step [100/135], Loss: 1.4051\n",
      "Epoch [17/100], Step [100/135], Loss: 1.4160\n",
      "Epoch [18/100], Step [100/135], Loss: 1.4064\n",
      "Epoch [19/100], Step [100/135], Loss: 1.4243\n",
      "Epoch [20/100], Step [100/135], Loss: 1.4078\n",
      "Epoch [21/100], Step [100/135], Loss: 1.4245\n",
      "Epoch [22/100], Step [100/135], Loss: 1.4186\n",
      "Epoch [23/100], Step [100/135], Loss: 1.4258\n",
      "Epoch [24/100], Step [100/135], Loss: 1.4269\n",
      "Epoch [25/100], Step [100/135], Loss: 1.4270\n",
      "Epoch [26/100], Step [100/135], Loss: 1.4270\n",
      "Epoch [27/100], Step [100/135], Loss: 1.4270\n",
      "Epoch [28/100], Step [100/135], Loss: 1.4270\n",
      "Epoch [29/100], Step [100/135], Loss: 1.4270\n",
      "Epoch [30/100], Step [100/135], Loss: 1.4270\n",
      "Epoch [31/100], Step [100/135], Loss: 1.4270\n",
      "Epoch [32/100], Step [100/135], Loss: 1.4269\n",
      "Epoch [33/100], Step [100/135], Loss: 1.4269\n",
      "Epoch [34/100], Step [100/135], Loss: 1.4269\n",
      "Epoch [35/100], Step [100/135], Loss: 1.4269\n",
      "Epoch [36/100], Step [100/135], Loss: 1.4269\n",
      "Epoch [37/100], Step [100/135], Loss: 1.4269\n",
      "Epoch [38/100], Step [100/135], Loss: 1.4269\n",
      "Epoch [39/100], Step [100/135], Loss: 1.4269\n",
      "Epoch [40/100], Step [100/135], Loss: 1.4286\n",
      "Epoch [41/100], Step [100/135], Loss: 1.4271\n",
      "Epoch [42/100], Step [100/135], Loss: 1.4285\n",
      "Epoch [43/100], Step [100/135], Loss: 1.4270\n",
      "Epoch [44/100], Step [100/135], Loss: 1.4284\n",
      "Epoch [45/100], Step [100/135], Loss: 1.4269\n",
      "Epoch [46/100], Step [100/135], Loss: 1.4284\n",
      "Epoch [47/100], Step [100/135], Loss: 1.4268\n",
      "Epoch [48/100], Step [100/135], Loss: 1.4283\n",
      "Epoch [49/100], Step [100/135], Loss: 1.4267\n",
      "Epoch [50/100], Step [100/135], Loss: 1.4282\n",
      "Epoch [51/100], Step [100/135], Loss: 1.4267\n",
      "Epoch [52/100], Step [100/135], Loss: 1.4282\n",
      "Epoch [53/100], Step [100/135], Loss: 1.4266\n",
      "Epoch [54/100], Step [100/135], Loss: 1.4281\n",
      "Epoch [55/100], Step [100/135], Loss: 1.4282\n",
      "Epoch [56/100], Step [100/135], Loss: 1.4265\n",
      "Epoch [57/100], Step [100/135], Loss: 1.4279\n",
      "Epoch [58/100], Step [100/135], Loss: 1.4024\n",
      "Epoch [59/100], Step [100/135], Loss: 1.4011\n",
      "Epoch [60/100], Step [100/135], Loss: 1.4010\n",
      "Epoch [61/100], Step [100/135], Loss: 1.4009\n",
      "Epoch [62/100], Step [100/135], Loss: 1.4009\n",
      "Epoch [63/100], Step [100/135], Loss: 1.4008\n",
      "Epoch [64/100], Step [100/135], Loss: 1.4008\n",
      "Epoch [65/100], Step [100/135], Loss: 1.4007\n",
      "Epoch [66/100], Step [100/135], Loss: 1.4007\n",
      "Epoch [67/100], Step [100/135], Loss: 1.4307\n",
      "Epoch [68/100], Step [100/135], Loss: 1.4028\n",
      "Epoch [69/100], Step [100/135], Loss: 1.4309\n",
      "Epoch [70/100], Step [100/135], Loss: 1.4281\n",
      "Epoch [71/100], Step [100/135], Loss: 1.4022\n",
      "Epoch [72/100], Step [100/135], Loss: 1.4308\n",
      "Epoch [73/100], Step [100/135], Loss: 1.4280\n",
      "Epoch [74/100], Step [100/135], Loss: 1.4274\n",
      "Epoch [75/100], Step [100/135], Loss: 1.4020\n",
      "Epoch [76/100], Step [100/135], Loss: 1.4306\n",
      "Epoch [77/100], Step [100/135], Loss: 1.4026\n",
      "Epoch [78/100], Step [100/135], Loss: 1.4307\n",
      "Epoch [79/100], Step [100/135], Loss: 1.4278\n",
      "Epoch [80/100], Step [100/135], Loss: 1.4273\n",
      "Epoch [81/100], Step [100/135], Loss: 1.4271\n",
      "Epoch [82/100], Step [100/135], Loss: 1.4019\n",
      "Epoch [83/100], Step [100/135], Loss: 1.4304\n",
      "Epoch [84/100], Step [100/135], Loss: 1.4276\n",
      "Epoch [85/100], Step [100/135], Loss: 1.4020\n",
      "Epoch [86/100], Step [100/135], Loss: 1.4278\n",
      "Epoch [87/100], Step [100/135], Loss: 1.4271\n",
      "Epoch [88/100], Step [100/135], Loss: 1.4269\n",
      "Epoch [89/100], Step [100/135], Loss: 1.4019\n",
      "Epoch [90/100], Step [100/135], Loss: 1.4277\n",
      "Epoch [91/100], Step [100/135], Loss: 1.4270\n",
      "Epoch [92/100], Step [100/135], Loss: 1.4268\n",
      "Epoch [93/100], Step [100/135], Loss: 1.4018\n",
      "Epoch [94/100], Step [100/135], Loss: 1.4276\n",
      "Epoch [95/100], Step [100/135], Loss: 1.4268\n",
      "Epoch [96/100], Step [100/135], Loss: 1.4267\n",
      "Epoch [97/100], Step [100/135], Loss: 1.4018\n",
      "Epoch [98/100], Step [100/135], Loss: 1.4275\n",
      "Epoch [99/100], Step [100/135], Loss: 1.4267\n",
      "Epoch [100/100], Step [100/135], Loss: 1.4265\n",
      "Test set: Average loss: 0.1034, Accuracy: 6/15 (40.00%)\n",
      "\n",
      "Epoch [1/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [2/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [3/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [4/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [5/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [6/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [7/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [8/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [9/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [10/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [11/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [12/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [13/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [14/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [15/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [16/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [17/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [18/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [19/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [20/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [21/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [22/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [23/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [24/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [25/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [26/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [27/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [28/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [29/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [30/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [31/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [32/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [33/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [34/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [35/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [36/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [37/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [38/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [39/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [40/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [41/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [42/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [43/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [44/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [45/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [46/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [47/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [48/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [49/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [50/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [51/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [52/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [53/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [54/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [55/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [56/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [57/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [58/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [59/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [60/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [61/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [62/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [63/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [64/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [65/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [66/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [67/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [68/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [69/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [70/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [71/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [72/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [73/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [74/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [75/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [76/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [77/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [78/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [79/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [80/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [81/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [82/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [83/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [84/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [85/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [86/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [87/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [88/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [89/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [90/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [91/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [92/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [93/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [94/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [95/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [96/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [97/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [98/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [99/100], Step [100/135], Loss: 1.1798\n",
      "Epoch [100/100], Step [100/135], Loss: 1.1798\n",
      "Test set: Average loss: 0.0368, Accuracy: 7/15 (46.67%)\n",
      "\n",
      "Epoch [1/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [2/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [3/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [4/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [5/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [6/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [7/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [8/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [9/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [10/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [11/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [12/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [13/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [14/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [15/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [16/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [17/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [18/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [19/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [20/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [21/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [22/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [23/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [24/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [25/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [26/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [27/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [28/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [29/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [30/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [31/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [32/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [33/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [34/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [35/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [36/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [37/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [38/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [39/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [40/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [41/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [42/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [43/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [44/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [45/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [46/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [47/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [48/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [49/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [50/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [51/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [52/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [53/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [54/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [55/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [56/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [57/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [58/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [59/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [60/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [61/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [62/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [63/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [64/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [65/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [66/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [67/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [68/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [69/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [70/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [71/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [72/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [73/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [74/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [75/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [76/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [77/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [78/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [79/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [80/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [81/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [82/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [83/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [84/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [85/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [86/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [87/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [88/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [89/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [90/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [91/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [92/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [93/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [94/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [95/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [96/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [97/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [98/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [99/100], Step [100/135], Loss: 1.5514\n",
      "Epoch [100/100], Step [100/135], Loss: 1.5514\n",
      "Test set: Average loss: 0.1034, Accuracy: 3/15 (20.00%)\n",
      "\n",
      "Epoch [1/100], Step [100/135], Loss: 0.9656\n",
      "Epoch [2/100], Step [100/135], Loss: 0.7112\n",
      "Epoch [3/100], Step [100/135], Loss: 0.6979\n",
      "Epoch [4/100], Step [100/135], Loss: 0.6737\n",
      "Epoch [5/100], Step [100/135], Loss: 0.6704\n",
      "Epoch [6/100], Step [100/135], Loss: 0.6764\n",
      "Epoch [7/100], Step [100/135], Loss: 0.7120\n",
      "Epoch [8/100], Step [100/135], Loss: 0.6710\n",
      "Epoch [9/100], Step [100/135], Loss: 0.7102\n",
      "Epoch [10/100], Step [100/135], Loss: 0.6707\n",
      "Epoch [11/100], Step [100/135], Loss: 0.7099\n",
      "Epoch [12/100], Step [100/135], Loss: 0.6706\n",
      "Epoch [13/100], Step [100/135], Loss: 0.7099\n",
      "Epoch [14/100], Step [100/135], Loss: 0.6705\n",
      "Epoch [15/100], Step [100/135], Loss: 0.7100\n",
      "Epoch [16/100], Step [100/135], Loss: 0.6705\n",
      "Epoch [17/100], Step [100/135], Loss: 0.7101\n",
      "Epoch [18/100], Step [100/135], Loss: 0.6705\n",
      "Epoch [19/100], Step [100/135], Loss: 0.7102\n",
      "Epoch [20/100], Step [100/135], Loss: 0.6705\n",
      "Epoch [21/100], Step [100/135], Loss: 0.7104\n",
      "Epoch [22/100], Step [100/135], Loss: 0.6705\n",
      "Epoch [23/100], Step [100/135], Loss: 0.7106\n",
      "Epoch [24/100], Step [100/135], Loss: 0.6706\n",
      "Epoch [25/100], Step [100/135], Loss: 0.7108\n",
      "Epoch [26/100], Step [100/135], Loss: 0.6706\n",
      "Epoch [27/100], Step [100/135], Loss: 0.7110\n",
      "Epoch [28/100], Step [100/135], Loss: 0.7141\n",
      "Epoch [29/100], Step [100/135], Loss: 0.6709\n",
      "Epoch [30/100], Step [100/135], Loss: 0.7105\n",
      "Epoch [31/100], Step [100/135], Loss: 0.6707\n",
      "Epoch [32/100], Step [100/135], Loss: 0.7108\n",
      "Epoch [33/100], Step [100/135], Loss: 0.6707\n",
      "Epoch [34/100], Step [100/135], Loss: 0.7112\n",
      "Epoch [35/100], Step [100/135], Loss: 0.6707\n",
      "Epoch [36/100], Step [100/135], Loss: 0.7115\n",
      "Epoch [37/100], Step [100/135], Loss: 0.6707\n",
      "Epoch [38/100], Step [100/135], Loss: 0.7118\n",
      "Epoch [39/100], Step [100/135], Loss: 0.7152\n",
      "Epoch [40/100], Step [100/135], Loss: 0.6711\n",
      "Epoch [41/100], Step [100/135], Loss: 0.7113\n",
      "Epoch [42/100], Step [100/135], Loss: 0.6708\n",
      "Epoch [43/100], Step [100/135], Loss: 0.7117\n",
      "Epoch [44/100], Step [100/135], Loss: 0.6708\n",
      "Epoch [45/100], Step [100/135], Loss: 0.7121\n",
      "Epoch [46/100], Step [100/135], Loss: 0.6708\n",
      "Epoch [47/100], Step [100/135], Loss: 0.7124\n",
      "Epoch [48/100], Step [100/135], Loss: 0.6708\n",
      "Epoch [49/100], Step [100/135], Loss: 0.7127\n",
      "Epoch [50/100], Step [100/135], Loss: 0.7537\n",
      "Epoch [51/100], Step [100/135], Loss: 0.6729\n",
      "Epoch [52/100], Step [100/135], Loss: 0.7123\n",
      "Epoch [53/100], Step [100/135], Loss: 0.6710\n",
      "Epoch [54/100], Step [100/135], Loss: 0.7123\n",
      "Epoch [55/100], Step [100/135], Loss: 0.6709\n",
      "Epoch [56/100], Step [100/135], Loss: 0.7495\n",
      "Epoch [57/100], Step [100/135], Loss: 0.6728\n",
      "Epoch [58/100], Step [100/135], Loss: 0.7499\n",
      "Epoch [59/100], Step [100/135], Loss: 0.6728\n",
      "Epoch [60/100], Step [100/135], Loss: 0.7498\n",
      "Epoch [61/100], Step [100/135], Loss: 0.6728\n",
      "Epoch [62/100], Step [100/135], Loss: 0.7498\n",
      "Epoch [63/100], Step [100/135], Loss: 0.6728\n",
      "Epoch [64/100], Step [100/135], Loss: 0.7499\n",
      "Epoch [65/100], Step [100/135], Loss: 0.6728\n",
      "Epoch [66/100], Step [100/135], Loss: 0.7500\n",
      "Epoch [67/100], Step [100/135], Loss: 0.6728\n",
      "Epoch [68/100], Step [100/135], Loss: 0.7502\n",
      "Epoch [69/100], Step [100/135], Loss: 0.6727\n",
      "Epoch [70/100], Step [100/135], Loss: 0.7504\n",
      "Epoch [71/100], Step [100/135], Loss: 0.6727\n",
      "Epoch [72/100], Step [100/135], Loss: 0.7505\n",
      "Epoch [73/100], Step [100/135], Loss: 0.6921\n",
      "Epoch [74/100], Step [100/135], Loss: 0.6699\n",
      "Epoch [75/100], Step [100/135], Loss: 0.7513\n",
      "Epoch [76/100], Step [100/135], Loss: 0.6724\n",
      "Epoch [77/100], Step [100/135], Loss: 0.7519\n",
      "Epoch [78/100], Step [100/135], Loss: 0.6918\n",
      "Epoch [79/100], Step [100/135], Loss: 0.7559\n",
      "Epoch [80/100], Step [100/135], Loss: 0.6918\n",
      "Epoch [81/100], Step [100/135], Loss: 0.6695\n",
      "Epoch [82/100], Step [100/135], Loss: 0.7518\n",
      "Epoch [83/100], Step [100/135], Loss: 0.6914\n",
      "Epoch [84/100], Step [100/135], Loss: 0.7565\n",
      "Epoch [85/100], Step [100/135], Loss: 0.6915\n",
      "Epoch [86/100], Step [100/135], Loss: 0.6691\n",
      "Epoch [87/100], Step [100/135], Loss: 0.7523\n",
      "Epoch [88/100], Step [100/135], Loss: 0.6911\n",
      "Epoch [89/100], Step [100/135], Loss: 0.7571\n",
      "Epoch [90/100], Step [100/135], Loss: 0.6961\n",
      "Epoch [91/100], Step [100/135], Loss: 0.6694\n",
      "Epoch [92/100], Step [100/135], Loss: 0.7528\n",
      "Epoch [93/100], Step [100/135], Loss: 0.6963\n",
      "Epoch [94/100], Step [100/135], Loss: 0.6692\n",
      "Epoch [95/100], Step [100/135], Loss: 0.7538\n",
      "Epoch [96/100], Step [100/135], Loss: 0.6965\n",
      "Epoch [97/100], Step [100/135], Loss: 0.6690\n",
      "Epoch [98/100], Step [100/135], Loss: 0.7545\n",
      "Epoch [99/100], Step [100/135], Loss: 0.6968\n",
      "Epoch [100/100], Step [100/135], Loss: 0.6688\n",
      "Test set: Average loss: 0.0368, Accuracy: 9/15 (60.00%)\n",
      "\n",
      "Epoch [1/100], Step [100/135], Loss: 1.1440\n",
      "Epoch [2/100], Step [100/135], Loss: 1.4050\n",
      "Epoch [3/100], Step [100/135], Loss: 1.4126\n",
      "Epoch [4/100], Step [100/135], Loss: 1.4090\n",
      "Epoch [5/100], Step [100/135], Loss: 1.4091\n",
      "Epoch [6/100], Step [100/135], Loss: 1.4098\n",
      "Epoch [7/100], Step [100/135], Loss: 1.4104\n",
      "Epoch [8/100], Step [100/135], Loss: 1.4110\n",
      "Epoch [9/100], Step [100/135], Loss: 1.4113\n",
      "Epoch [10/100], Step [100/135], Loss: 1.4117\n",
      "Epoch [11/100], Step [100/135], Loss: 1.4119\n",
      "Epoch [12/100], Step [100/135], Loss: 1.4121\n",
      "Epoch [13/100], Step [100/135], Loss: 1.4123\n",
      "Epoch [14/100], Step [100/135], Loss: 1.4124\n",
      "Epoch [15/100], Step [100/135], Loss: 1.4125\n",
      "Epoch [16/100], Step [100/135], Loss: 1.4126\n",
      "Epoch [17/100], Step [100/135], Loss: 1.4127\n",
      "Epoch [18/100], Step [100/135], Loss: 1.4128\n",
      "Epoch [19/100], Step [100/135], Loss: 1.3267\n",
      "Epoch [20/100], Step [100/135], Loss: 1.3405\n",
      "Epoch [21/100], Step [100/135], Loss: 1.4098\n",
      "Epoch [22/100], Step [100/135], Loss: 1.4039\n",
      "Epoch [23/100], Step [100/135], Loss: 1.4124\n",
      "Epoch [24/100], Step [100/135], Loss: 1.4165\n",
      "Epoch [25/100], Step [100/135], Loss: 1.4188\n",
      "Epoch [26/100], Step [100/135], Loss: 1.4196\n",
      "Epoch [27/100], Step [100/135], Loss: 1.4200\n",
      "Epoch [28/100], Step [100/135], Loss: 1.4202\n",
      "Epoch [29/100], Step [100/135], Loss: 1.4204\n",
      "Epoch [30/100], Step [100/135], Loss: 1.4205\n",
      "Epoch [31/100], Step [100/135], Loss: 1.4206\n",
      "Epoch [32/100], Step [100/135], Loss: 1.4207\n",
      "Epoch [33/100], Step [100/135], Loss: 1.3228\n",
      "Epoch [34/100], Step [100/135], Loss: 1.3387\n",
      "Epoch [35/100], Step [100/135], Loss: 1.4102\n",
      "Epoch [36/100], Step [100/135], Loss: 1.3628\n",
      "Epoch [37/100], Step [100/135], Loss: 1.4127\n",
      "Epoch [38/100], Step [100/135], Loss: 1.3638\n",
      "Epoch [39/100], Step [100/135], Loss: 1.4126\n",
      "Epoch [40/100], Step [100/135], Loss: 1.3634\n",
      "Epoch [41/100], Step [100/135], Loss: 1.4123\n",
      "Epoch [42/100], Step [100/135], Loss: 1.3630\n",
      "Epoch [43/100], Step [100/135], Loss: 1.4121\n",
      "Epoch [44/100], Step [100/135], Loss: 1.3627\n",
      "Epoch [45/100], Step [100/135], Loss: 1.4118\n",
      "Epoch [46/100], Step [100/135], Loss: 1.3623\n",
      "Epoch [47/100], Step [100/135], Loss: 1.4116\n",
      "Epoch [48/100], Step [100/135], Loss: 1.3620\n",
      "Epoch [49/100], Step [100/135], Loss: 1.4240\n",
      "Epoch [50/100], Step [100/135], Loss: 1.3696\n",
      "Epoch [51/100], Step [100/135], Loss: 1.4128\n",
      "Epoch [52/100], Step [100/135], Loss: 1.3625\n",
      "Epoch [53/100], Step [100/135], Loss: 1.4243\n",
      "Epoch [54/100], Step [100/135], Loss: 1.3696\n",
      "Epoch [55/100], Step [100/135], Loss: 1.4129\n",
      "Epoch [56/100], Step [100/135], Loss: 1.3622\n",
      "Epoch [57/100], Step [100/135], Loss: 1.4244\n",
      "Epoch [58/100], Step [100/135], Loss: 1.3694\n",
      "Epoch [59/100], Step [100/135], Loss: 1.4128\n",
      "Epoch [60/100], Step [100/135], Loss: 1.3620\n",
      "Epoch [61/100], Step [100/135], Loss: 1.4245\n",
      "Epoch [62/100], Step [100/135], Loss: 1.3693\n",
      "Epoch [63/100], Step [100/135], Loss: 1.4127\n",
      "Epoch [64/100], Step [100/135], Loss: 1.3617\n",
      "Epoch [65/100], Step [100/135], Loss: 1.4175\n",
      "Epoch [66/100], Step [100/135], Loss: 1.3641\n",
      "Epoch [67/100], Step [100/135], Loss: 1.4178\n",
      "Epoch [68/100], Step [100/135], Loss: 1.3642\n",
      "Epoch [69/100], Step [100/135], Loss: 1.4178\n",
      "Epoch [70/100], Step [100/135], Loss: 1.3640\n",
      "Epoch [71/100], Step [100/135], Loss: 1.4178\n",
      "Epoch [72/100], Step [100/135], Loss: 1.3639\n",
      "Epoch [73/100], Step [100/135], Loss: 1.4177\n",
      "Epoch [74/100], Step [100/135], Loss: 1.3637\n",
      "Epoch [75/100], Step [100/135], Loss: 1.4176\n",
      "Epoch [76/100], Step [100/135], Loss: 1.3635\n",
      "Epoch [77/100], Step [100/135], Loss: 1.4176\n",
      "Epoch [78/100], Step [100/135], Loss: 1.3633\n",
      "Epoch [79/100], Step [100/135], Loss: 1.4175\n",
      "Epoch [80/100], Step [100/135], Loss: 1.3631\n",
      "Epoch [81/100], Step [100/135], Loss: 1.4174\n",
      "Epoch [82/100], Step [100/135], Loss: 1.3629\n",
      "Epoch [83/100], Step [100/135], Loss: 1.4173\n",
      "Epoch [84/100], Step [100/135], Loss: 1.3627\n",
      "Epoch [85/100], Step [100/135], Loss: 1.4173\n",
      "Epoch [86/100], Step [100/135], Loss: 1.3625\n",
      "Epoch [87/100], Step [100/135], Loss: 1.4172\n",
      "Epoch [88/100], Step [100/135], Loss: 1.3623\n",
      "Epoch [89/100], Step [100/135], Loss: 1.4171\n",
      "Epoch [90/100], Step [100/135], Loss: 1.3621\n",
      "Epoch [91/100], Step [100/135], Loss: 1.4170\n",
      "Epoch [92/100], Step [100/135], Loss: 1.3619\n",
      "Epoch [93/100], Step [100/135], Loss: 1.4169\n",
      "Epoch [94/100], Step [100/135], Loss: 1.3617\n",
      "Epoch [95/100], Step [100/135], Loss: 1.4168\n",
      "Epoch [96/100], Step [100/135], Loss: 1.3615\n",
      "Epoch [97/100], Step [100/135], Loss: 1.4167\n",
      "Epoch [98/100], Step [100/135], Loss: 1.3613\n",
      "Epoch [99/100], Step [100/135], Loss: 1.4166\n",
      "Epoch [100/100], Step [100/135], Loss: 1.3611\n",
      "Test set: Average loss: 0.1034, Accuracy: 5/15 (33.33%)\n",
      "\n",
      "Epoch [1/100], Step [100/135], Loss: 1.1132\n",
      "Epoch [2/100], Step [100/135], Loss: 1.3300\n",
      "Epoch [3/100], Step [100/135], Loss: 1.3800\n",
      "Epoch [4/100], Step [100/135], Loss: 1.4293\n",
      "Epoch [5/100], Step [100/135], Loss: 1.3459\n",
      "Epoch [6/100], Step [100/135], Loss: 1.4222\n",
      "Epoch [7/100], Step [100/135], Loss: 1.4017\n",
      "Epoch [8/100], Step [100/135], Loss: 1.4002\n",
      "Epoch [9/100], Step [100/135], Loss: 1.4000\n",
      "Epoch [10/100], Step [100/135], Loss: 1.4056\n",
      "Epoch [11/100], Step [100/135], Loss: 1.3949\n",
      "Epoch [12/100], Step [100/135], Loss: 1.4042\n",
      "Epoch [13/100], Step [100/135], Loss: 1.3945\n",
      "Epoch [14/100], Step [100/135], Loss: 1.3907\n",
      "Epoch [15/100], Step [100/135], Loss: 1.4029\n",
      "Epoch [16/100], Step [100/135], Loss: 1.3939\n",
      "Epoch [17/100], Step [100/135], Loss: 1.3903\n",
      "Epoch [18/100], Step [100/135], Loss: 1.3890\n",
      "Epoch [19/100], Step [100/135], Loss: 1.4021\n",
      "Epoch [20/100], Step [100/135], Loss: 1.3933\n",
      "Epoch [21/100], Step [100/135], Loss: 1.3898\n",
      "Epoch [22/100], Step [100/135], Loss: 1.3885\n",
      "Epoch [23/100], Step [100/135], Loss: 1.3879\n",
      "Epoch [24/100], Step [100/135], Loss: 1.4013\n",
      "Epoch [25/100], Step [100/135], Loss: 1.3925\n",
      "Epoch [26/100], Step [100/135], Loss: 1.3891\n",
      "Epoch [27/100], Step [100/135], Loss: 1.3877\n",
      "Epoch [28/100], Step [100/135], Loss: 1.3871\n",
      "Epoch [29/100], Step [100/135], Loss: 1.4005\n",
      "Epoch [30/100], Step [100/135], Loss: 1.3918\n",
      "Epoch [31/100], Step [100/135], Loss: 1.3883\n",
      "Epoch [32/100], Step [100/135], Loss: 1.3870\n",
      "Epoch [33/100], Step [100/135], Loss: 1.3864\n",
      "Epoch [34/100], Step [100/135], Loss: 1.3860\n",
      "Epoch [35/100], Step [100/135], Loss: 1.3995\n",
      "Epoch [36/100], Step [100/135], Loss: 1.3908\n",
      "Epoch [37/100], Step [100/135], Loss: 1.3873\n",
      "Epoch [38/100], Step [100/135], Loss: 1.3860\n",
      "Epoch [39/100], Step [100/135], Loss: 1.3854\n",
      "Epoch [40/100], Step [100/135], Loss: 1.3851\n",
      "Epoch [41/100], Step [100/135], Loss: 1.3848\n",
      "Epoch [42/100], Step [100/135], Loss: 1.3846\n",
      "Epoch [43/100], Step [100/135], Loss: 1.3981\n",
      "Epoch [44/100], Step [100/135], Loss: 1.3894\n",
      "Epoch [45/100], Step [100/135], Loss: 1.3859\n",
      "Epoch [46/100], Step [100/135], Loss: 1.3846\n",
      "Epoch [47/100], Step [100/135], Loss: 1.3840\n",
      "Epoch [48/100], Step [100/135], Loss: 1.3837\n",
      "Epoch [49/100], Step [100/135], Loss: 1.3834\n",
      "Epoch [50/100], Step [100/135], Loss: 1.3832\n",
      "Epoch [51/100], Step [100/135], Loss: 1.3830\n",
      "Epoch [52/100], Step [100/135], Loss: 1.3966\n",
      "Epoch [53/100], Step [100/135], Loss: 1.3878\n",
      "Epoch [54/100], Step [100/135], Loss: 1.3844\n",
      "Epoch [55/100], Step [100/135], Loss: 1.3830\n",
      "Epoch [56/100], Step [100/135], Loss: 1.3825\n",
      "Epoch [57/100], Step [100/135], Loss: 1.3821\n",
      "Epoch [58/100], Step [100/135], Loss: 1.3819\n",
      "Epoch [59/100], Step [100/135], Loss: 1.3817\n",
      "Epoch [60/100], Step [100/135], Loss: 1.3814\n",
      "Epoch [61/100], Step [100/135], Loss: 1.3812\n",
      "Epoch [62/100], Step [100/135], Loss: 1.3810\n",
      "Epoch [63/100], Step [100/135], Loss: 1.3947\n",
      "Epoch [64/100], Step [100/135], Loss: 1.3858\n",
      "Epoch [65/100], Step [100/135], Loss: 1.3824\n",
      "Epoch [66/100], Step [100/135], Loss: 1.3811\n",
      "Epoch [67/100], Step [100/135], Loss: 1.3805\n",
      "Epoch [68/100], Step [100/135], Loss: 1.3802\n",
      "Epoch [69/100], Step [100/135], Loss: 1.3799\n",
      "Epoch [70/100], Step [100/135], Loss: 1.3797\n",
      "Epoch [71/100], Step [100/135], Loss: 1.3795\n",
      "Epoch [72/100], Step [100/135], Loss: 1.3793\n",
      "Epoch [73/100], Step [100/135], Loss: 1.3791\n",
      "Epoch [74/100], Step [100/135], Loss: 1.3789\n",
      "Epoch [75/100], Step [100/135], Loss: 1.3926\n",
      "Epoch [76/100], Step [100/135], Loss: 1.3837\n",
      "Epoch [77/100], Step [100/135], Loss: 1.3802\n",
      "Epoch [78/100], Step [100/135], Loss: 1.3789\n",
      "Epoch [79/100], Step [100/135], Loss: 1.3783\n",
      "Epoch [80/100], Step [100/135], Loss: 1.3780\n",
      "Epoch [81/100], Step [100/135], Loss: 1.3777\n",
      "Epoch [82/100], Step [100/135], Loss: 1.3775\n",
      "Epoch [83/100], Step [100/135], Loss: 1.3773\n",
      "Epoch [84/100], Step [100/135], Loss: 1.3771\n",
      "Epoch [85/100], Step [100/135], Loss: 1.3769\n",
      "Epoch [86/100], Step [100/135], Loss: 1.3767\n",
      "Epoch [87/100], Step [100/135], Loss: 1.3765\n",
      "Epoch [88/100], Step [100/135], Loss: 1.3903\n",
      "Epoch [89/100], Step [100/135], Loss: 1.3812\n",
      "Epoch [90/100], Step [100/135], Loss: 1.3778\n",
      "Epoch [91/100], Step [100/135], Loss: 1.3765\n",
      "Epoch [92/100], Step [100/135], Loss: 1.3759\n",
      "Epoch [93/100], Step [100/135], Loss: 1.3755\n",
      "Epoch [94/100], Step [100/135], Loss: 1.3753\n",
      "Epoch [95/100], Step [100/135], Loss: 1.3751\n",
      "Epoch [96/100], Step [100/135], Loss: 1.3748\n",
      "Epoch [97/100], Step [100/135], Loss: 1.3746\n",
      "Epoch [98/100], Step [100/135], Loss: 1.3744\n",
      "Epoch [99/100], Step [100/135], Loss: 1.3883\n",
      "Epoch [100/100], Step [100/135], Loss: 1.3792\n",
      "Test set: Average loss: 0.1034, Accuracy: 6/15 (40.00%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sampo.scheduler.selection.neural_net import one_hot_encode, cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "s = cross_val_score(train_dataset=train_dataset,\n",
    "                      target_column='label',\n",
    "                      model=model,\n",
    "                      epochs=100,\n",
    "                      folds=10,\n",
    "                      shuffle=True,\n",
    "                      random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T16:33:50.888163Z",
     "start_time": "2023-08-28T16:32:34.871009100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33.333333333333336, 40.0, 33.333333333333336, 40.0, 40.0, 46.666666666666664, 20.0, 60.0, 33.333333333333336, 40.0]\n"
     ]
    }
   ],
   "source": [
    "print(s)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T16:34:05.388475Z",
     "start_time": "2023-08-28T16:34:05.372698900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
