{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "input_parameters = 16\n",
    "layer_size = 5\n",
    "layer_count = 3\n",
    "classification_size = 3\n",
    "learning_rate = 0.001"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-11T07:57:06.261457700Z",
     "start_time": "2023-09-11T07:57:05.846583600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "[Parameter containing:\n tensor([[-0.2100, -0.1244,  0.0220, -0.0849, -0.1574,  0.0088, -0.0629,  0.1967,\n          -0.1288, -0.1301,  0.2261, -0.1873,  0.2161,  0.1020, -0.1734, -0.0661],\n         [ 0.2192, -0.1905, -0.0533, -0.1130,  0.0320,  0.1710,  0.1457, -0.0213,\n           0.2274, -0.2092,  0.0759, -0.1546, -0.1239,  0.2200, -0.1501,  0.0068],\n         [ 0.0864, -0.0886, -0.0517,  0.1582,  0.1452,  0.1101,  0.1746, -0.0774,\n          -0.0244, -0.1887, -0.1840, -0.0239,  0.0890,  0.1626, -0.1164,  0.2184],\n         [ 0.1208,  0.1637, -0.0332,  0.2450, -0.2058, -0.2074,  0.2132,  0.0677,\n          -0.2267,  0.0814,  0.1517,  0.2028, -0.0826,  0.0235, -0.0264, -0.1279],\n         [-0.1119,  0.2070, -0.0171, -0.1136,  0.0886,  0.2438, -0.0881, -0.0781,\n           0.0739, -0.0509,  0.1496,  0.1920,  0.0119,  0.1623, -0.0273,  0.0594]],\n        requires_grad=True),\n Parameter containing:\n tensor([-0.0758, -0.2095,  0.1700, -0.2471,  0.1162], requires_grad=True)]"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sampo.scheduler.selection.neural_net import NeuralNet, load_dataset\n",
    "\n",
    "model = NeuralNet(input_parameters, layer_size, layer_count, classification_size)\n",
    "list(model.parameters())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-11T07:57:09.626759800Z",
     "start_time": "2023-09-11T07:57:06.468110200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Step [100/2250], Loss: 1.5508\n",
      "Epoch [1/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [1/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [1/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [1/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [1/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [1/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [1/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [1/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [1/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [1/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [1/100], Step [1200/2250], Loss: 0.5534\n",
      "Epoch [1/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [1/100], Step [1400/2250], Loss: 0.5781\n",
      "Epoch [1/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [1/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [1/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [1/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [1/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [1/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [1/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [1/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [2/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [2/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [2/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [2/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [2/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [2/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [2/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [2/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [2/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [2/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [2/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [2/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [2/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [2/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [2/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [2/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [2/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [2/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [2/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [2/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [2/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [2/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [3/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [3/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [3/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [3/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [3/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [3/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [3/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [3/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [3/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [3/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [3/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [3/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [3/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [3/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [3/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [3/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [3/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [3/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [3/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [3/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [3/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [3/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [4/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [4/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [4/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [4/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [4/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [4/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [4/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [4/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [4/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [4/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [4/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [4/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [4/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [4/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [4/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [4/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [4/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [4/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [4/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [4/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [4/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [4/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [5/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [5/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [5/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [5/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [5/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [5/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [5/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [5/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [5/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [5/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [5/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [5/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [5/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [5/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [5/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [5/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [5/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [5/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [5/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [5/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [5/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [5/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [6/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [6/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [6/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [6/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [6/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [6/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [6/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [6/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [6/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [6/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [6/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [6/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [6/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [6/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [6/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [6/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [6/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [6/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [6/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [6/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [6/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [6/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [7/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [7/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [7/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [7/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [7/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [7/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [7/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [7/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [7/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [7/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [7/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [7/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [7/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [7/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [7/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [7/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [7/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [7/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [7/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [7/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [7/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [7/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [8/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [8/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [8/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [8/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [8/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [8/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [8/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [8/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [8/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [8/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [8/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [8/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [8/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [8/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [8/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [8/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [8/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [8/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [8/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [8/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [8/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [8/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [9/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [9/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [9/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [9/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [9/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [9/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [9/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [9/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [9/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [9/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [9/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [9/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [9/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [9/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [9/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [9/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [9/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [9/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [9/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [9/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [9/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [9/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [10/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [10/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [10/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [10/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [10/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [10/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [10/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [10/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [10/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [10/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [10/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [10/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [10/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [10/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [10/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [10/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [10/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [10/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [10/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [10/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [10/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [10/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [11/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [11/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [11/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [11/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [11/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [11/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [11/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [11/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [11/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [11/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [11/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [11/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [11/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [11/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [11/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [11/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [11/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [11/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [11/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [11/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [11/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [11/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [12/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [12/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [12/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [12/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [12/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [12/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [12/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [12/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [12/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [12/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [12/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [12/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [12/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [12/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [12/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [12/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [12/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [12/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [12/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [12/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [12/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [12/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [13/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [13/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [13/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [13/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [13/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [13/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [13/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [13/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [13/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [13/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [13/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [13/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [13/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [13/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [13/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [13/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [13/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [13/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [13/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [13/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [13/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [13/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [14/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [14/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [14/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [14/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [14/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [14/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [14/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [14/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [14/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [14/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [14/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [14/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [14/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [14/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [14/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [14/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [14/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [14/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [14/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [14/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [14/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [14/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [15/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [15/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [15/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [15/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [15/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [15/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [15/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [15/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [15/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [15/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [15/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [15/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [15/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [15/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [15/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [15/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [15/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [15/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [15/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [15/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [15/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [15/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [16/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [16/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [16/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [16/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [16/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [16/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [16/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [16/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [16/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [16/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [16/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [16/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [16/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [16/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [16/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [16/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [16/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [16/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [16/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [16/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [16/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [16/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [17/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [17/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [17/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [17/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [17/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [17/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [17/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [17/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [17/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [17/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [17/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [17/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [17/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [17/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [17/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [17/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [17/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [17/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [17/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [17/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [17/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [17/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [18/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [18/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [18/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [18/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [18/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [18/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [18/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [18/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [18/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [18/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [18/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [18/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [18/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [18/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [18/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [18/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [18/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [18/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [18/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [18/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [18/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [18/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [19/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [19/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [19/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [19/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [19/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [19/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [19/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [19/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [19/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [19/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [19/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [19/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [19/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [19/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [19/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [19/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [19/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [19/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [19/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [19/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [19/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [19/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [20/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [20/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [20/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [20/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [20/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [20/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [20/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [20/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [20/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [20/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [20/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [20/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [20/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [20/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [20/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [20/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [20/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [20/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [20/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [20/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [20/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [20/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [21/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [21/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [21/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [21/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [21/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [21/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [21/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [21/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [21/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [21/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [21/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [21/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [21/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [21/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [21/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [21/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [21/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [21/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [21/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [21/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [21/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [21/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [22/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [22/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [22/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [22/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [22/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [22/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [22/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [22/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [22/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [22/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [22/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [22/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [22/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [22/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [22/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [22/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [22/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [22/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [22/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [22/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [22/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [22/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [23/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [23/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [23/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [23/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [23/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [23/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [23/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [23/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [23/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [23/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [23/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [23/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [23/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [23/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [23/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [23/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [23/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [23/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [23/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [23/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [23/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [23/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [24/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [24/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [24/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [24/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [24/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [24/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [24/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [24/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [24/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [24/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [24/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [24/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [24/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [24/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [24/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [24/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [24/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [24/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [24/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [24/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [24/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [24/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [25/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [25/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [25/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [25/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [25/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [25/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [25/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [25/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [25/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [25/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [25/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [25/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [25/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [25/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [25/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [25/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [25/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [25/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [25/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [25/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [25/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [25/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [26/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [26/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [26/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [26/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [26/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [26/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [26/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [26/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [26/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [26/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [26/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [26/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [26/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [26/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [26/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [26/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [26/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [26/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [26/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [26/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [26/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [26/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [27/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [27/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [27/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [27/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [27/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [27/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [27/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [27/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [27/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [27/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [27/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [27/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [27/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [27/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [27/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [27/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [27/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [27/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [27/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [27/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [27/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [27/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [28/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [28/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [28/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [28/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [28/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [28/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [28/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [28/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [28/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [28/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [28/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [28/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [28/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [28/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [28/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [28/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [28/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [28/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [28/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [28/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [28/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [28/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [29/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [29/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [29/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [29/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [29/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [29/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [29/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [29/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [29/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [29/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [29/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [29/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [29/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [29/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [29/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [29/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [29/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [29/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [29/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [29/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [29/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [29/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [30/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [30/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [30/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [30/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [30/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [30/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [30/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [30/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [30/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [30/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [30/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [30/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [30/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [30/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [30/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [30/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [30/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [30/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [30/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [30/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [30/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [30/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [31/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [31/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [31/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [31/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [31/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [31/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [31/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [31/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [31/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [31/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [31/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [31/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [31/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [31/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [31/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [31/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [31/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [31/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [31/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [31/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [31/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [31/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [32/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [32/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [32/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [32/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [32/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [32/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [32/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [32/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [32/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [32/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [32/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [32/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [32/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [32/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [32/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [32/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [32/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [32/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [32/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [32/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [32/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [32/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [33/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [33/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [33/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [33/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [33/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [33/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [33/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [33/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [33/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [33/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [33/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [33/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [33/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [33/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [33/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [33/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [33/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [33/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [33/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [33/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [33/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [33/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [34/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [34/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [34/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [34/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [34/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [34/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [34/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [34/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [34/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [34/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [34/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [34/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [34/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [34/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [34/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [34/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [34/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [34/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [34/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [34/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [34/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [34/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [35/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [35/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [35/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [35/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [35/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [35/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [35/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [35/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [35/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [35/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [35/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [35/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [35/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [35/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [35/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [35/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [35/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [35/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [35/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [35/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [35/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [35/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [36/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [36/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [36/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [36/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [36/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [36/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [36/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [36/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [36/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [36/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [36/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [36/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [36/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [36/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [36/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [36/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [36/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [36/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [36/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [36/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [36/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [36/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [37/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [37/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [37/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [37/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [37/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [37/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [37/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [37/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [37/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [37/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [37/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [37/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [37/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [37/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [37/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [37/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [37/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [37/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [37/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [37/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [37/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [37/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [38/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [38/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [38/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [38/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [38/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [38/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [38/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [38/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [38/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [38/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [38/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [38/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [38/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [38/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [38/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [38/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [38/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [38/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [38/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [38/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [38/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [38/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [39/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [39/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [39/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [39/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [39/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [39/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [39/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [39/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [39/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [39/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [39/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [39/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [39/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [39/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [39/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [39/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [39/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [39/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [39/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [39/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [39/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [39/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [40/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [40/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [40/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [40/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [40/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [40/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [40/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [40/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [40/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [40/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [40/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [40/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [40/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [40/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [40/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [40/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [40/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [40/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [40/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [40/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [40/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [40/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [41/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [41/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [41/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [41/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [41/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [41/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [41/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [41/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [41/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [41/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [41/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [41/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [41/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [41/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [41/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [41/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [41/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [41/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [41/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [41/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [41/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [41/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [42/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [42/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [42/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [42/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [42/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [42/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [42/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [42/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [42/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [42/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [42/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [42/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [42/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [42/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [42/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [42/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [42/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [42/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [42/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [42/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [42/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [42/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [43/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [43/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [43/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [43/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [43/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [43/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [43/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [43/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [43/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [43/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [43/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [43/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [43/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [43/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [43/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [43/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [43/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [43/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [43/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [43/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [43/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [43/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [44/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [44/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [44/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [44/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [44/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [44/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [44/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [44/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [44/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [44/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [44/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [44/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [44/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [44/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [44/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [44/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [44/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [44/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [44/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [44/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [44/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [44/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [45/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [45/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [45/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [45/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [45/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [45/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [45/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [45/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [45/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [45/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [45/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [45/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [45/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [45/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [45/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [45/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [45/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [45/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [45/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [45/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [45/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [45/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [46/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [46/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [46/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [46/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [46/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [46/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [46/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [46/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [46/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [46/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [46/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [46/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [46/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [46/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [46/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [46/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [46/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [46/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [46/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [46/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [46/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [46/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [47/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [47/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [47/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [47/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [47/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [47/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [47/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [47/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [47/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [47/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [47/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [47/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [47/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [47/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [47/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [47/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [47/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [47/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [47/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [47/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [47/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [47/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [48/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [48/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [48/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [48/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [48/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [48/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [48/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [48/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [48/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [48/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [48/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [48/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [48/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [48/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [48/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [48/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [48/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [48/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [48/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [48/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [48/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [48/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [49/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [49/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [49/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [49/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [49/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [49/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [49/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [49/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [49/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [49/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [49/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [49/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [49/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [49/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [49/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [49/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [49/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [49/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [49/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [49/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [49/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [49/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [50/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [50/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [50/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [50/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [50/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [50/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [50/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [50/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [50/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [50/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [50/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [50/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [50/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [50/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [50/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [50/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [50/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [50/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [50/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [50/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [50/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [50/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [51/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [51/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [51/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [51/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [51/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [51/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [51/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [51/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [51/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [51/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [51/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [51/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [51/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [51/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [51/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [51/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [51/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [51/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [51/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [51/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [51/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [51/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [52/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [52/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [52/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [52/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [52/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [52/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [52/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [52/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [52/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [52/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [52/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [52/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [52/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [52/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [52/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [52/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [52/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [52/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [52/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [52/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [52/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [52/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [53/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [53/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [53/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [53/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [53/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [53/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [53/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [53/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [53/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [53/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [53/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [53/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [53/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [53/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [53/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [53/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [53/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [53/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [53/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [53/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [53/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [53/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [54/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [54/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [54/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [54/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [54/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [54/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [54/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [54/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [54/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [54/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [54/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [54/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [54/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [54/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [54/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [54/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [54/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [54/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [54/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [54/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [54/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [54/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [55/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [55/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [55/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [55/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [55/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [55/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [55/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [55/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [55/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [55/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [55/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [55/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [55/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [55/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [55/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [55/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [55/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [55/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [55/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [55/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [55/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [55/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [56/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [56/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [56/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [56/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [56/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [56/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [56/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [56/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [56/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [56/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [56/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [56/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [56/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [56/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [56/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [56/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [56/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [56/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [56/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [56/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [56/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [56/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [57/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [57/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [57/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [57/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [57/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [57/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [57/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [57/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [57/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [57/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [57/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [57/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [57/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [57/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [57/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [57/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [57/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [57/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [57/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [57/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [57/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [57/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [58/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [58/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [58/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [58/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [58/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [58/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [58/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [58/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [58/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [58/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [58/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [58/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [58/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [58/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [58/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [58/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [58/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [58/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [58/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [58/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [58/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [58/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [59/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [59/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [59/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [59/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [59/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [59/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [59/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [59/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [59/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [59/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [59/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [59/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [59/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [59/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [59/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [59/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [59/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [59/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [59/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [59/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [59/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [59/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [60/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [60/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [60/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [60/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [60/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [60/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [60/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [60/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [60/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [60/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [60/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [60/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [60/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [60/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [60/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [60/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [60/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [60/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [60/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [60/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [60/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [60/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [61/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [61/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [61/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [61/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [61/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [61/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [61/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [61/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [61/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [61/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [61/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [61/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [61/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [61/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [61/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [61/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [61/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [61/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [61/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [61/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [61/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [61/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [62/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [62/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [62/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [62/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [62/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [62/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [62/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [62/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [62/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [62/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [62/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [62/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [62/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [62/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [62/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [62/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [62/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [62/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [62/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [62/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [62/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [62/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [63/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [63/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [63/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [63/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [63/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [63/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [63/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [63/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [63/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [63/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [63/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [63/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [63/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [63/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [63/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [63/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [63/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [63/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [63/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [63/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [63/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [63/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [64/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [64/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [64/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [64/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [64/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [64/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [64/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [64/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [64/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [64/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [64/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [64/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [64/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [64/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [64/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [64/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [64/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [64/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [64/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [64/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [64/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [64/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [65/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [65/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [65/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [65/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [65/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [65/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [65/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [65/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [65/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [65/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [65/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [65/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [65/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [65/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [65/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [65/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [65/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [65/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [65/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [65/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [65/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [65/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [66/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [66/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [66/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [66/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [66/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [66/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [66/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [66/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [66/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [66/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [66/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [66/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [66/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [66/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [66/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [66/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [66/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [66/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [66/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [66/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [66/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [66/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [67/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [67/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [67/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [67/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [67/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [67/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [67/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [67/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [67/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [67/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [67/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [67/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [67/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [67/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [67/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [67/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [67/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [67/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [67/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [67/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [67/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [67/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [68/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [68/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [68/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [68/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [68/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [68/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [68/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [68/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [68/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [68/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [68/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [68/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [68/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [68/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [68/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [68/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [68/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [68/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [68/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [68/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [68/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [68/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [69/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [69/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [69/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [69/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [69/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [69/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [69/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [69/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [69/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [69/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [69/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [69/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [69/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [69/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [69/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [69/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [69/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [69/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [69/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [69/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [69/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [69/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [70/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [70/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [70/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [70/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [70/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [70/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [70/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [70/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [70/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [70/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [70/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [70/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [70/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [70/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [70/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [70/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [70/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [70/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [70/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [70/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [70/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [70/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [71/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [71/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [71/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [71/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [71/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [71/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [71/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [71/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [71/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [71/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [71/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [71/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [71/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [71/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [71/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [71/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [71/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [71/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [71/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [71/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [71/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [71/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [72/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [72/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [72/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [72/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [72/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [72/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [72/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [72/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [72/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [72/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [72/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [72/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [72/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [72/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [72/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [72/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [72/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [72/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [72/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [72/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [72/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [72/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [73/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [73/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [73/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [73/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [73/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [73/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [73/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [73/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [73/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [73/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [73/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [73/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [73/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [73/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [73/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [73/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [73/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [73/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [73/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [73/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [73/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [73/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [74/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [74/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [74/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [74/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [74/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [74/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [74/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [74/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [74/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [74/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [74/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [74/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [74/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [74/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [74/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [74/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [74/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [74/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [74/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [74/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [74/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [74/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [75/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [75/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [75/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [75/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [75/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [75/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [75/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [75/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [75/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [75/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [75/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [75/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [75/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [75/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [75/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [75/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [75/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [75/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [75/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [75/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [75/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [75/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [76/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [76/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [76/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [76/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [76/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [76/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [76/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [76/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [76/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [76/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [76/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [76/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [76/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [76/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [76/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [76/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [76/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [76/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [76/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [76/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [76/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [76/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [77/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [77/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [77/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [77/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [77/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [77/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [77/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [77/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [77/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [77/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [77/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [77/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [77/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [77/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [77/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [77/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [77/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [77/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [77/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [77/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [77/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [77/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [78/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [78/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [78/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [78/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [78/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [78/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [78/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [78/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [78/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [78/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [78/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [78/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [78/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [78/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [78/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [78/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [78/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [78/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [78/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [78/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [78/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [78/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [79/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [79/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [79/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [79/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [79/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [79/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [79/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [79/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [79/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [79/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [79/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [79/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [79/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [79/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [79/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [79/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [79/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [79/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [79/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [79/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [79/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [79/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [80/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [80/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [80/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [80/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [80/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [80/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [80/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [80/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [80/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [80/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [80/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [80/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [80/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [80/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [80/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [80/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [80/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [80/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [80/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [80/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [80/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [80/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [81/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [81/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [81/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [81/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [81/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [81/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [81/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [81/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [81/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [81/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [81/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [81/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [81/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [81/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [81/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [81/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [81/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [81/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [81/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [81/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [81/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [81/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [82/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [82/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [82/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [82/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [82/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [82/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [82/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [82/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [82/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [82/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [82/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [82/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [82/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [82/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [82/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [82/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [82/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [82/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [82/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [82/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [82/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [82/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [83/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [83/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [83/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [83/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [83/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [83/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [83/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [83/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [83/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [83/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [83/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [83/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [83/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [83/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [83/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [83/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [83/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [83/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [83/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [83/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [83/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [83/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [84/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [84/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [84/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [84/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [84/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [84/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [84/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [84/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [84/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [84/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [84/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [84/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [84/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [84/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [84/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [84/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [84/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [84/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [84/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [84/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [84/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [84/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [85/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [85/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [85/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [85/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [85/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [85/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [85/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [85/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [85/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [85/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [85/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [85/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [85/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [85/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [85/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [85/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [85/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [85/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [85/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [85/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [85/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [85/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [86/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [86/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [86/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [86/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [86/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [86/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [86/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [86/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [86/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [86/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [86/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [86/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [86/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [86/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [86/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [86/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [86/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [86/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [86/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [86/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [86/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [86/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [87/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [87/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [87/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [87/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [87/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [87/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [87/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [87/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [87/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [87/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [87/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [87/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [87/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [87/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [87/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [87/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [87/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [87/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [87/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [87/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [87/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [87/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [88/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [88/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [88/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [88/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [88/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [88/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [88/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [88/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [88/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [88/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [88/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [88/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [88/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [88/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [88/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [88/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [88/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [88/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [88/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [88/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [88/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [88/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [89/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [89/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [89/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [89/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [89/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [89/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [89/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [89/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [89/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [89/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [89/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [89/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [89/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [89/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [89/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [89/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [89/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [89/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [89/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [89/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [89/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [89/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [90/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [90/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [90/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [90/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [90/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [90/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [90/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [90/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [90/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [90/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [90/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [90/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [90/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [90/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [90/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [90/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [90/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [90/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [90/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [90/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [90/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [90/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [91/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [91/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [91/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [91/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [91/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [91/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [91/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [91/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [91/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [91/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [91/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [91/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [91/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [91/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [91/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [91/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [91/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [91/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [91/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [91/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [91/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [91/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [92/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [92/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [92/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [92/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [92/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [92/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [92/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [92/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [92/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [92/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [92/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [92/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [92/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [92/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [92/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [92/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [92/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [92/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [92/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [92/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [92/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [92/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [93/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [93/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [93/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [93/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [93/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [93/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [93/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [93/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [93/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [93/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [93/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [93/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [93/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [93/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [93/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [93/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [93/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [93/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [93/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [93/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [93/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [93/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [94/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [94/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [94/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [94/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [94/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [94/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [94/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [94/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [94/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [94/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [94/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [94/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [94/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [94/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [94/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [94/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [94/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [94/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [94/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [94/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [94/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [94/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [95/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [95/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [95/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [95/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [95/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [95/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [95/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [95/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [95/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [95/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [95/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [95/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [95/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [95/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [95/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [95/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [95/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [95/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [95/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [95/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [95/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [95/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [96/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [96/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [96/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [96/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [96/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [96/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [96/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [96/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [96/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [96/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [96/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [96/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [96/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [96/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [96/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [96/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [96/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [96/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [96/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [96/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [96/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [96/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [97/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [97/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [97/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [97/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [97/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [97/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [97/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [97/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [97/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [97/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [97/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [97/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [97/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [97/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [97/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [97/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [97/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [97/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [97/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [97/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [97/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [97/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [98/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [98/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [98/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [98/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [98/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [98/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [98/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [98/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [98/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [98/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [98/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [98/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [98/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [98/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [98/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [98/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [98/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [98/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [98/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [98/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [98/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [98/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [99/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [99/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [99/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [99/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [99/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [99/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [99/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [99/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [99/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [99/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [99/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [99/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [99/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [99/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [99/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [99/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [99/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [99/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [99/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [99/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [99/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [99/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [100/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [100/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [100/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [100/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [100/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [100/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [100/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [100/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [100/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [100/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [100/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [100/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [100/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [100/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [100/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [100/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [100/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [100/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [100/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [100/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [100/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [100/100], Step [2200/2250], Loss: 1.1344\n"
     ]
    },
    {
     "data": {
      "text/plain": "[Parameter containing:\n tensor([[ 0.1069,  0.1460, -0.0022,  0.2634,  0.0178, -0.1918,  0.1584, -0.1053,\n           0.2493,  0.1505,  0.2430,  0.0284,  0.1678, -0.1975, -0.0486,  0.1325],\n         [ 0.0380, -0.1496, -0.2851, -0.0233,  0.1676,  0.0444, -0.0736,  0.0382,\n           0.1514,  0.1394, -0.0708,  0.1247, -0.2421,  0.1449, -0.0123,  0.0960],\n         [ 0.0670,  0.0949,  0.1137,  0.0395, -0.1552, -0.0542, -0.0881,  0.2164,\n          -0.2392, -0.0585,  0.0526, -0.1061, -0.0562,  0.0464, -0.1048,  0.0935],\n         [ 0.2430,  0.2600,  0.2973,  0.1004,  0.1952, -0.0921,  0.0226,  0.0020,\n           0.2400,  0.0142,  0.3396, -0.0108, -0.0947,  0.0045,  0.0669,  0.1761],\n         [ 0.2038,  0.1505, -0.0443,  0.0812,  0.2444, -0.1617, -0.0390, -0.0957,\n           0.1464,  0.2715,  0.0769, -0.0567,  0.1308, -0.0767, -0.0310,  0.1968]],\n        requires_grad=True),\n Parameter containing:\n tensor([-0.0940, -0.1481,  0.1454,  0.3313,  0.0796], requires_grad=True)]"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for i in range(10):\n",
    "#     print(f'Loop {i}/10')\n",
    "x_train, x_test, y_train, y_test = load_dataset('dataset.csv')\n",
    "model.fit(x_train, y_train, 100)\n",
    "list(model.parameters())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T14:26:41.513226200Z",
     "start_time": "2023-08-30T14:26:41.055213300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "[tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.])]"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T14:26:42.398321100Z",
     "start_time": "2023-08-30T14:26:42.383354900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NeuralNet' object has no attribute 'score'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscore\u001B[49m(x_test, y_test)\n",
      "File \u001B[1;32m~\\PycharmProjects\\sampo\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1614\u001B[0m, in \u001B[0;36mModule.__getattr__\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m   1612\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m modules:\n\u001B[0;32m   1613\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m modules[name]\n\u001B[1;32m-> 1614\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m object has no attribute \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m   1615\u001B[0m     \u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, name))\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'NeuralNet' object has no attribute 'score'"
     ]
    }
   ],
   "source": [
    "model.score(x_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T14:27:06.443447700Z",
     "start_time": "2023-08-30T14:27:06.413133400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sampo.scheduler.selection.neural_net import NeuralNet\n",
    "\n",
    "train_dataset = pd.read_csv('dataset.csv', index_col='index')\n",
    "for col in train_dataset.columns[:-1]:\n",
    "    train_dataset[col] = train_dataset[col].apply(lambda x: float(x))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-11T09:02:35.980081700Z",
     "start_time": "2023-09-11T09:02:34.096528800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "input_parameters = 14\n",
    "layer_size = 5\n",
    "layer_count = 3\n",
    "classification_size = 2\n",
    "learning_rate = 0.02\n",
    "\n",
    "model = NeuralNet(input_parameters, layer_size, layer_count, classification_size, learning_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-11T09:26:43.869253600Z",
     "start_time": "2023-09-11T09:26:43.861886600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "           0         1     2          3     4    5    6    7      8      9  \\\nindex                                                                        \n516    113.0  1.004548  36.0  32.212389  36.0  1.0  1.0  3.0   61.0  478.0   \n930     42.0  1.516754  26.0  40.666667  26.0  1.0  1.0  2.0   51.0  181.0   \n2       40.0  1.793230  25.0  45.962500  25.0  1.0  1.0  2.0   49.0  163.0   \n589    212.0  0.832533  82.0  29.412736  82.0  1.0  1.0  4.0  134.0  587.0   \n515    112.0  1.005797  40.0  31.468750  40.0  1.0  1.0  3.0   69.0  292.0   \n...      ...       ...   ...        ...   ...  ...  ...  ...    ...    ...   \n1651   187.0  0.848599  82.0  29.681818  82.0  1.0  1.0  3.0   82.0  478.0   \n1918   129.0  1.140898  39.0  35.170543  39.0  1.0  1.0  3.0   79.0  544.0   \n1804   132.0  1.014176  56.0  33.015152  56.0  1.0  1.0  4.0  113.0  403.0   \n1704   165.0  0.913429  36.0  30.918182  36.0  1.0  1.0  3.0   68.0  330.0   \n1593   199.0  0.595570  76.0  26.123116  76.0  1.0  1.0  3.0   86.0  502.0   \n\n           10      11     12     13  label  \nindex                                       \n516     661.0   957.0  162.0    0.0      0  \n930     181.0   146.0    0.0    0.0      0  \n2       163.0   130.0    0.0    0.0      0  \n589    1044.0  1168.0  388.0    0.0      0  \n515     553.0   613.0  226.0    0.0      0  \n...       ...     ...    ...    ...    ...  \n1651   1008.0  1152.0  516.0    0.0      1  \n1918    809.0  1117.0  226.0    0.0      1  \n1804    645.0   745.0  178.0    0.0      1  \n1704    578.0  1027.0  647.0  306.0      1  \n1593   1260.0  1428.0  740.0    0.0      1  \n\n[2000 rows x 15 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n      <th>label</th>\n    </tr>\n    <tr>\n      <th>index</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>516</th>\n      <td>113.0</td>\n      <td>1.004548</td>\n      <td>36.0</td>\n      <td>32.212389</td>\n      <td>36.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>61.0</td>\n      <td>478.0</td>\n      <td>661.0</td>\n      <td>957.0</td>\n      <td>162.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>930</th>\n      <td>42.0</td>\n      <td>1.516754</td>\n      <td>26.0</td>\n      <td>40.666667</td>\n      <td>26.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>51.0</td>\n      <td>181.0</td>\n      <td>181.0</td>\n      <td>146.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>40.0</td>\n      <td>1.793230</td>\n      <td>25.0</td>\n      <td>45.962500</td>\n      <td>25.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>49.0</td>\n      <td>163.0</td>\n      <td>163.0</td>\n      <td>130.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>589</th>\n      <td>212.0</td>\n      <td>0.832533</td>\n      <td>82.0</td>\n      <td>29.412736</td>\n      <td>82.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>134.0</td>\n      <td>587.0</td>\n      <td>1044.0</td>\n      <td>1168.0</td>\n      <td>388.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>515</th>\n      <td>112.0</td>\n      <td>1.005797</td>\n      <td>40.0</td>\n      <td>31.468750</td>\n      <td>40.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>69.0</td>\n      <td>292.0</td>\n      <td>553.0</td>\n      <td>613.0</td>\n      <td>226.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1651</th>\n      <td>187.0</td>\n      <td>0.848599</td>\n      <td>82.0</td>\n      <td>29.681818</td>\n      <td>82.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>82.0</td>\n      <td>478.0</td>\n      <td>1008.0</td>\n      <td>1152.0</td>\n      <td>516.0</td>\n      <td>0.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1918</th>\n      <td>129.0</td>\n      <td>1.140898</td>\n      <td>39.0</td>\n      <td>35.170543</td>\n      <td>39.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>79.0</td>\n      <td>544.0</td>\n      <td>809.0</td>\n      <td>1117.0</td>\n      <td>226.0</td>\n      <td>0.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1804</th>\n      <td>132.0</td>\n      <td>1.014176</td>\n      <td>56.0</td>\n      <td>33.015152</td>\n      <td>56.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>113.0</td>\n      <td>403.0</td>\n      <td>645.0</td>\n      <td>745.0</td>\n      <td>178.0</td>\n      <td>0.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1704</th>\n      <td>165.0</td>\n      <td>0.913429</td>\n      <td>36.0</td>\n      <td>30.918182</td>\n      <td>36.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>68.0</td>\n      <td>330.0</td>\n      <td>578.0</td>\n      <td>1027.0</td>\n      <td>647.0</td>\n      <td>306.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1593</th>\n      <td>199.0</td>\n      <td>0.595570</td>\n      <td>76.0</td>\n      <td>26.123116</td>\n      <td>76.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>86.0</td>\n      <td>502.0</td>\n      <td>1260.0</td>\n      <td>1428.0</td>\n      <td>740.0</td>\n      <td>0.0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>2000 rows  15 columns</p>\n</div>"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-11T09:26:44.188102100Z",
     "start_time": "2023-09-11T09:26:44.140866Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/1000], Loss: 0.8162\n",
      "Epoch [1/10], Step [200/1000], Loss: 0.8162\n",
      "Epoch [1/10], Step [300/1000], Loss: 0.8162\n",
      "Epoch [1/10], Step [400/1000], Loss: 0.8162\n",
      "Epoch [1/10], Step [500/1000], Loss: 0.5836\n",
      "Epoch [1/10], Step [600/1000], Loss: 0.5836\n",
      "Epoch [1/10], Step [700/1000], Loss: 0.5836\n",
      "Epoch [1/10], Step [800/1000], Loss: 0.5836\n",
      "Epoch [1/10], Step [900/1000], Loss: 0.5836\n",
      "Epoch [1/10], Step [1000/1000], Loss: 0.5836\n",
      "Epoch [2/10], Step [100/1000], Loss: 0.8162\n",
      "Epoch [2/10], Step [200/1000], Loss: 0.8162\n",
      "Epoch [2/10], Step [300/1000], Loss: 0.8162\n",
      "Epoch [2/10], Step [400/1000], Loss: 0.8162\n",
      "Epoch [2/10], Step [500/1000], Loss: 0.5836\n",
      "Epoch [2/10], Step [600/1000], Loss: 0.5836\n",
      "Epoch [2/10], Step [700/1000], Loss: 0.5836\n",
      "Epoch [2/10], Step [800/1000], Loss: 0.5836\n",
      "Epoch [2/10], Step [900/1000], Loss: 0.5836\n",
      "Epoch [2/10], Step [1000/1000], Loss: 0.5836\n",
      "Epoch [3/10], Step [100/1000], Loss: 0.8162\n",
      "Epoch [3/10], Step [200/1000], Loss: 0.8162\n",
      "Epoch [3/10], Step [300/1000], Loss: 0.8162\n",
      "Epoch [3/10], Step [400/1000], Loss: 0.8162\n",
      "Epoch [3/10], Step [500/1000], Loss: 0.5836\n",
      "Epoch [3/10], Step [600/1000], Loss: 0.5836\n",
      "Epoch [3/10], Step [700/1000], Loss: 0.5836\n",
      "Epoch [3/10], Step [800/1000], Loss: 0.5836\n",
      "Epoch [3/10], Step [900/1000], Loss: 0.5836\n",
      "Epoch [3/10], Step [1000/1000], Loss: 0.5836\n",
      "Epoch [4/10], Step [100/1000], Loss: 0.8162\n",
      "Epoch [4/10], Step [200/1000], Loss: 0.8162\n",
      "Epoch [4/10], Step [300/1000], Loss: 0.8162\n",
      "Epoch [4/10], Step [400/1000], Loss: 0.8162\n",
      "Epoch [4/10], Step [500/1000], Loss: 0.5836\n",
      "Epoch [4/10], Step [600/1000], Loss: 0.5836\n",
      "Epoch [4/10], Step [700/1000], Loss: 0.5836\n",
      "Epoch [4/10], Step [800/1000], Loss: 0.5836\n",
      "Epoch [4/10], Step [900/1000], Loss: 0.5836\n",
      "Epoch [4/10], Step [1000/1000], Loss: 0.5836\n",
      "Epoch [5/10], Step [100/1000], Loss: 0.8162\n",
      "Epoch [5/10], Step [200/1000], Loss: 0.8162\n",
      "Epoch [5/10], Step [300/1000], Loss: 0.8162\n",
      "Epoch [5/10], Step [400/1000], Loss: 0.8162\n",
      "Epoch [5/10], Step [500/1000], Loss: 0.5836\n",
      "Epoch [5/10], Step [600/1000], Loss: 0.5836\n",
      "Epoch [5/10], Step [700/1000], Loss: 0.5836\n",
      "Epoch [5/10], Step [800/1000], Loss: 0.5836\n",
      "Epoch [5/10], Step [900/1000], Loss: 0.5836\n",
      "Epoch [5/10], Step [1000/1000], Loss: 0.5836\n",
      "Epoch [6/10], Step [100/1000], Loss: 0.8162\n",
      "Epoch [6/10], Step [200/1000], Loss: 0.8162\n",
      "Epoch [6/10], Step [300/1000], Loss: 0.8162\n",
      "Epoch [6/10], Step [400/1000], Loss: 0.8162\n",
      "Epoch [6/10], Step [500/1000], Loss: 0.5836\n",
      "Epoch [6/10], Step [600/1000], Loss: 0.5836\n",
      "Epoch [6/10], Step [700/1000], Loss: 0.5836\n",
      "Epoch [6/10], Step [800/1000], Loss: 0.5836\n",
      "Epoch [6/10], Step [900/1000], Loss: 0.5836\n",
      "Epoch [6/10], Step [1000/1000], Loss: 0.5836\n",
      "Epoch [7/10], Step [100/1000], Loss: 0.8162\n",
      "Epoch [7/10], Step [200/1000], Loss: 0.8162\n",
      "Epoch [7/10], Step [300/1000], Loss: 0.8162\n",
      "Epoch [7/10], Step [400/1000], Loss: 0.8162\n",
      "Epoch [7/10], Step [500/1000], Loss: 0.5836\n",
      "Epoch [7/10], Step [600/1000], Loss: 0.5836\n",
      "Epoch [7/10], Step [700/1000], Loss: 0.5836\n",
      "Epoch [7/10], Step [800/1000], Loss: 0.5836\n",
      "Epoch [7/10], Step [900/1000], Loss: 0.5836\n",
      "Epoch [7/10], Step [1000/1000], Loss: 0.5836\n",
      "Epoch [8/10], Step [100/1000], Loss: 0.8162\n",
      "Epoch [8/10], Step [200/1000], Loss: 0.8162\n",
      "Epoch [8/10], Step [300/1000], Loss: 0.8162\n",
      "Epoch [8/10], Step [400/1000], Loss: 0.8162\n",
      "Epoch [8/10], Step [500/1000], Loss: 0.5836\n",
      "Epoch [8/10], Step [600/1000], Loss: 0.5836\n",
      "Epoch [8/10], Step [700/1000], Loss: 0.5836\n",
      "Epoch [8/10], Step [800/1000], Loss: 0.5836\n",
      "Epoch [8/10], Step [900/1000], Loss: 0.5836\n",
      "Epoch [8/10], Step [1000/1000], Loss: 0.5836\n",
      "Epoch [9/10], Step [100/1000], Loss: 0.8162\n",
      "Epoch [9/10], Step [200/1000], Loss: 0.8162\n",
      "Epoch [9/10], Step [300/1000], Loss: 0.8162\n",
      "Epoch [9/10], Step [400/1000], Loss: 0.8162\n",
      "Epoch [9/10], Step [500/1000], Loss: 0.5836\n",
      "Epoch [9/10], Step [600/1000], Loss: 0.5836\n",
      "Epoch [9/10], Step [700/1000], Loss: 0.5836\n",
      "Epoch [9/10], Step [800/1000], Loss: 0.5836\n",
      "Epoch [9/10], Step [900/1000], Loss: 0.5836\n",
      "Epoch [9/10], Step [1000/1000], Loss: 0.5836\n",
      "Epoch [10/10], Step [100/1000], Loss: 0.8162\n",
      "Epoch [10/10], Step [200/1000], Loss: 0.8162\n",
      "Epoch [10/10], Step [300/1000], Loss: 0.8162\n",
      "Epoch [10/10], Step [400/1000], Loss: 0.8162\n",
      "Epoch [10/10], Step [500/1000], Loss: 0.5836\n",
      "Epoch [10/10], Step [600/1000], Loss: 0.5836\n",
      "Epoch [10/10], Step [700/1000], Loss: 0.5836\n",
      "Epoch [10/10], Step [800/1000], Loss: 0.5836\n",
      "Epoch [10/10], Step [900/1000], Loss: 0.5836\n",
      "Epoch [10/10], Step [1000/1000], Loss: 0.5836\n",
      "Epoch [1/10], Step [100/1000], Loss: 0.8162\n",
      "Epoch [1/10], Step [200/1000], Loss: 0.8162\n",
      "Epoch [1/10], Step [300/1000], Loss: 0.8162\n",
      "Epoch [1/10], Step [400/1000], Loss: 0.8162\n",
      "Epoch [1/10], Step [500/1000], Loss: 0.8162\n",
      "Epoch [1/10], Step [600/1000], Loss: 0.5836\n",
      "Epoch [1/10], Step [700/1000], Loss: 0.5836\n",
      "Epoch [1/10], Step [800/1000], Loss: 0.5836\n",
      "Epoch [1/10], Step [900/1000], Loss: 0.5836\n",
      "Epoch [1/10], Step [1000/1000], Loss: 0.5836\n",
      "Epoch [2/10], Step [100/1000], Loss: 0.8162\n",
      "Epoch [2/10], Step [200/1000], Loss: 0.8162\n",
      "Epoch [2/10], Step [300/1000], Loss: 0.8162\n",
      "Epoch [2/10], Step [400/1000], Loss: 0.8162\n",
      "Epoch [2/10], Step [500/1000], Loss: 0.8162\n",
      "Epoch [2/10], Step [600/1000], Loss: 0.5836\n",
      "Epoch [2/10], Step [700/1000], Loss: 0.5836\n",
      "Epoch [2/10], Step [800/1000], Loss: 0.5836\n",
      "Epoch [2/10], Step [900/1000], Loss: 0.5836\n",
      "Epoch [2/10], Step [1000/1000], Loss: 0.5836\n",
      "Epoch [3/10], Step [100/1000], Loss: 0.8162\n",
      "Epoch [3/10], Step [200/1000], Loss: 0.8162\n",
      "Epoch [3/10], Step [300/1000], Loss: 0.8162\n",
      "Epoch [3/10], Step [400/1000], Loss: 0.8162\n",
      "Epoch [3/10], Step [500/1000], Loss: 0.8162\n",
      "Epoch [3/10], Step [600/1000], Loss: 0.5836\n",
      "Epoch [3/10], Step [700/1000], Loss: 0.5836\n",
      "Epoch [3/10], Step [800/1000], Loss: 0.5836\n",
      "Epoch [3/10], Step [900/1000], Loss: 0.5836\n",
      "Epoch [3/10], Step [1000/1000], Loss: 0.5836\n",
      "Epoch [4/10], Step [100/1000], Loss: 0.8162\n",
      "Epoch [4/10], Step [200/1000], Loss: 0.8162\n",
      "Epoch [4/10], Step [300/1000], Loss: 0.8162\n",
      "Epoch [4/10], Step [400/1000], Loss: 0.8162\n",
      "Epoch [4/10], Step [500/1000], Loss: 0.8162\n",
      "Epoch [4/10], Step [600/1000], Loss: 0.5836\n",
      "Epoch [4/10], Step [700/1000], Loss: 0.5836\n",
      "Epoch [4/10], Step [800/1000], Loss: 0.5836\n",
      "Epoch [4/10], Step [900/1000], Loss: 0.5836\n",
      "Epoch [4/10], Step [1000/1000], Loss: 0.5836\n",
      "Epoch [5/10], Step [100/1000], Loss: 0.8162\n",
      "Epoch [5/10], Step [200/1000], Loss: 0.8162\n",
      "Epoch [5/10], Step [300/1000], Loss: 0.8162\n",
      "Epoch [5/10], Step [400/1000], Loss: 0.8162\n",
      "Epoch [5/10], Step [500/1000], Loss: 0.8162\n",
      "Epoch [5/10], Step [600/1000], Loss: 0.5836\n",
      "Epoch [5/10], Step [700/1000], Loss: 0.5836\n",
      "Epoch [5/10], Step [800/1000], Loss: 0.5836\n",
      "Epoch [5/10], Step [900/1000], Loss: 0.5836\n",
      "Epoch [5/10], Step [1000/1000], Loss: 0.5836\n",
      "Epoch [6/10], Step [100/1000], Loss: 0.8162\n",
      "Epoch [6/10], Step [200/1000], Loss: 0.8162\n",
      "Epoch [6/10], Step [300/1000], Loss: 0.8162\n",
      "Epoch [6/10], Step [400/1000], Loss: 0.8162\n",
      "Epoch [6/10], Step [500/1000], Loss: 0.8162\n",
      "Epoch [6/10], Step [600/1000], Loss: 0.5836\n",
      "Epoch [6/10], Step [700/1000], Loss: 0.5836\n",
      "Epoch [6/10], Step [800/1000], Loss: 0.5836\n",
      "Epoch [6/10], Step [900/1000], Loss: 0.5836\n",
      "Epoch [6/10], Step [1000/1000], Loss: 0.5836\n",
      "Epoch [7/10], Step [100/1000], Loss: 0.8162\n",
      "Epoch [7/10], Step [200/1000], Loss: 0.8162\n",
      "Epoch [7/10], Step [300/1000], Loss: 0.8162\n",
      "Epoch [7/10], Step [400/1000], Loss: 0.8162\n",
      "Epoch [7/10], Step [500/1000], Loss: 0.8162\n",
      "Epoch [7/10], Step [600/1000], Loss: 0.5836\n",
      "Epoch [7/10], Step [700/1000], Loss: 0.5836\n",
      "Epoch [7/10], Step [800/1000], Loss: 0.5836\n",
      "Epoch [7/10], Step [900/1000], Loss: 0.5836\n",
      "Epoch [7/10], Step [1000/1000], Loss: 0.5836\n",
      "Epoch [8/10], Step [100/1000], Loss: 0.8162\n",
      "Epoch [8/10], Step [200/1000], Loss: 0.8162\n",
      "Epoch [8/10], Step [300/1000], Loss: 0.8162\n",
      "Epoch [8/10], Step [400/1000], Loss: 0.8162\n",
      "Epoch [8/10], Step [500/1000], Loss: 0.8162\n",
      "Epoch [8/10], Step [600/1000], Loss: 0.5836\n",
      "Epoch [8/10], Step [700/1000], Loss: 0.5836\n",
      "Epoch [8/10], Step [800/1000], Loss: 0.5836\n",
      "Epoch [8/10], Step [900/1000], Loss: 0.5836\n",
      "Epoch [8/10], Step [1000/1000], Loss: 0.5836\n",
      "Epoch [9/10], Step [100/1000], Loss: 0.8162\n",
      "Epoch [9/10], Step [200/1000], Loss: 0.8162\n",
      "Epoch [9/10], Step [300/1000], Loss: 0.8162\n",
      "Epoch [9/10], Step [400/1000], Loss: 0.8162\n",
      "Epoch [9/10], Step [500/1000], Loss: 0.8162\n",
      "Epoch [9/10], Step [600/1000], Loss: 0.5836\n",
      "Epoch [9/10], Step [700/1000], Loss: 0.5836\n",
      "Epoch [9/10], Step [800/1000], Loss: 0.5836\n",
      "Epoch [9/10], Step [900/1000], Loss: 0.5836\n",
      "Epoch [9/10], Step [1000/1000], Loss: 0.5836\n",
      "Epoch [10/10], Step [100/1000], Loss: 0.8162\n",
      "Epoch [10/10], Step [200/1000], Loss: 0.8162\n",
      "Epoch [10/10], Step [300/1000], Loss: 0.8162\n",
      "Epoch [10/10], Step [400/1000], Loss: 0.8162\n",
      "Epoch [10/10], Step [500/1000], Loss: 0.8162\n",
      "Epoch [10/10], Step [600/1000], Loss: 0.5836\n",
      "Epoch [10/10], Step [700/1000], Loss: 0.5836\n",
      "Epoch [10/10], Step [800/1000], Loss: 0.5836\n",
      "Epoch [10/10], Step [900/1000], Loss: 0.5836\n",
      "Epoch [10/10], Step [1000/1000], Loss: 0.5836\n"
     ]
    }
   ],
   "source": [
    "from sampo.scheduler.selection.validation import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "s = cross_val_score(train_dataset=train_dataset,\n",
    "                    target_column='label',\n",
    "                    scorer=accuracy_score,\n",
    "                    model=model,\n",
    "                    epochs=10,\n",
    "                    folds=2,\n",
    "                    shuffle=True,\n",
    "                    random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-11T09:26:56.616445100Z",
     "start_time": "2023-09-11T09:26:44.835025100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.493, 0.507]\n"
     ]
    }
   ],
   "source": [
    "print(s)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-11T09:27:04.954471400Z",
     "start_time": "2023-09-11T09:27:04.938850500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "[Parameter containing:\n tensor([[ 0.0853, -0.2358, -0.1703,  0.2243, -0.2182,  0.1229,  0.2254,  0.1496,\n          -0.1528, -0.0671, -0.1860,  0.1216, -0.2457,  0.0007],\n         [-0.0704,  0.0304, -0.1792, -0.2293,  0.0054,  0.0559,  0.2444,  0.0365,\n           0.0626, -0.1570, -0.1961,  0.2441,  0.1735,  0.2596],\n         [-0.1242,  0.0564, -0.0854,  0.1854, -0.1849,  0.1263, -0.0422,  0.0448,\n          -0.0589,  0.1168,  0.1434,  0.1404, -0.0857,  0.2098],\n         [-0.2239,  0.2198, -0.0439,  0.2020, -0.1687, -0.0022, -0.2456,  0.0985,\n           0.2317, -0.1285,  0.1458,  0.2660,  0.2238, -0.1352],\n         [ 0.1087,  0.0138, -0.1094, -0.0517, -0.1234,  0.0105,  0.0728, -0.0206,\n          -0.2072,  0.0056, -0.0541,  0.1592,  0.0062,  0.0059]],\n        requires_grad=True),\n Parameter containing:\n tensor([-0.2208, -0.0790,  0.2164, -0.1480, -0.2058], requires_grad=True)]"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-11T09:19:10.165040500Z",
     "start_time": "2023-09-11T09:19:10.133792100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
